The,O
initial,O
learning,B-DeepLearning
rate,I-DeepLearning
was,O
set,O
to,O
0.0005,O
as,O
shown,O
in,O
Table,O
1,O
.,O
Deep,O
Voice,O
3,O
is,O
a,O
fully,O
convolutional,B-DeepLearning
architecture,O
for,O
speech,O
synthesis,O
.,O
Its,O
character-to-spectrogram,O
architecture,O
enables,O
fully,O
parallel,O
computation,O
and,O
the,O
training,O
is,O
much,O
faster,O
than,O
at,O
the,O
RNN,B-DeepLearning
architectures,O
.,O
Those,O
features,O
are,O
in,O
a,O
key,O
value,O
form,O
and,O
they,O
are,O
fed,O
into,O
the,O
attention-based,B-DeepLearning
decoder,I-DeepLearning
.,O
The,O
hidden,B-DeepLearning
layers,I-DeepLearning
of,O
the,O
decoder,B-DeepLearning
are,O
fed,O
into,O
the,O
third,O
converter,O
layer,O
which,O
is,O
capable,O
of,O
predicting,O
the,O
acoustic,O
features,O
for,O
waveform,O
synthesis,O
.,O
The,O
training,B-DeepLearning
of,I-DeepLearning
the,I-DeepLearning
model,I-DeepLearning
is,O
followed,O
by,O
validation,B-DeepLearning
which,O
means,O
that,O
each,O
10K,O
steps,B-DeepLearning
are,O
evaluated,O
before,O
the,O
training,B-DeepLearning
process,O
proceeds,O
.,O
The,O
evaluation,O
is,O
done,O
on,O
external,O
unknown,O
sentences,O
that,O
provide,O
insight,O
into,O
the,O
advancement,O
of,O
the,O
learnt,O
dependencies,O
between,O
the,O
dataset,O
and,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
weights,I-DeepLearning
.,O
Deep,O
Voice,O
3,O
suggested,O
that,O
parameters,B-DeepLearning
worked,O
perfectly,O
for,O
our,O
model,O
thus,O
we,O
used,O
the,O
same,O
hyperparameters,B-DeepLearning
without,O
increasing,O
the,O
demand,O
due,O
to,O
our,O
resource,O
limitations,O
.,O
The,O
model,O
started,O
to,O
produce,O
an,O
intelligible,O
understandable,O
and,O
partially,O
human-like,O
speech,O
after,O
50,O
K,O
steps,B-DeepLearning
as,O
observed,O
from,O
the,O
figure,O
.,O
Loss,B-DeepLearning
function,I-DeepLearning
is,O
a,O
metric,O
that,O
refers,O
to,O
the,O
accuracy,B-DeepLearning
of,O
the,O
prediction,B-DeepLearning
.,O
The,O
main,O
objective,O
is,O
to,O
minimize,O
the,O
model,B-DeepLearning
errors,O
or,O
minimize,O
the,O
loss,B-DeepLearning
function,I-DeepLearning
.,O
In,O
our,O
case,O
the,O
loss,B-DeepLearning
functions,I-DeepLearning
behaves,O
in,O
a,O
desired,O
manner,O
it,O
gradually,O
decreases,O
converging,B-DeepLearning
to,O
a,O
value,O
of,O
0.1731,O
after,O
162.2,O
K,O
steps,B-DeepLearning
in,O
four,O
days,O
and,O
11,O
h,O
of,O
training,B-DeepLearning
.,O
Learning,B-DeepLearning
rate,I-DeepLearning
plays,O
a,O
vital,O
role,O
in,O
minimizing,O
the,O
loss,B-DeepLearning
function,I-DeepLearning
.,O
The,O
gradient,B-DeepLearning
norm,I-DeepLearning
that,O
is,O
presented,O
in,O
the,O
same,O
figure,O
calculates,O
the,O
L2,B-DeepLearning
norm,O
of,O
the,O
gradients,B-DeepLearning
of,O
the,O
last,B-DeepLearning
layer,I-DeepLearning
of,O
the,O
Deep,B-DeepLearning
learning,I-DeepLearning
network,I-DeepLearning
.,O
It,O
is,O
an,O
indicator,O
showing,O
whether,O
the,O
weights,B-DeepLearning
of,O
the,O
Deep,B-DeepLearning
learning,I-DeepLearning
network,I-DeepLearning
are,O
properly,O
updated,O
.,O
This,O
problem,O
affects,O
the,O
upper,O
layers,B-DeepLearning
of,O
the,O
Deep,B-DeepLearning
learning,I-DeepLearning
network,I-DeepLearning
making,O
it,O
really,O
hard,O
for,O
the,O
network,O
to,O
learn,O
and,O
tune,O
the,O
parameters,B-DeepLearning
.,O
In,O
such,O
case,O
the,O
model,O
is,O
unstable,O
and,O
it,O
is,O
not,O
able,O
to,O
learn,O
from,O
data,O
since,O
the,O
accumulation,O
of,O
large,O
error,B-DeepLearning
gradients,I-DeepLearning
during,O
the,O
training,B-DeepLearning
process,I-DeepLearning
result,O
in,O
very,O
large,O
updates,O
in,O
the,O
Deep,B-DeepLearning
learning,I-DeepLearning
model,I-DeepLearning
weights,I-DeepLearning
.,O
By,O
principles,O
of,O
transfer,B-DeepLearning
learning,I-DeepLearning
we,O
tried,O
to,O
fine-tune,B-DeepLearning
the,O
Russian,O
TTS,B-DeepLearning
model,I-DeepLearning
.,O
So,O
as,O
to,O
automatically,O
and,O
accurately,O
classify,O
the,O
FCGR,O
encoded,O
data,O
we,O
experimentally,O
compared,O
Multilayer,B-DeepLearning
Perceptron,I-DeepLearning
Artificial,B-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
MLP-ANN,B-DeepLearning
Support,O
Vector,O
Machine,O
SVM,O
and,O
Naïve,O
Bayes,O
NB,O
which,O
are,O
frontline,O
pattern,O
recognition,O
tools,O
in,O
machine,B-DeepLearning
learning,I-DeepLearning
.,O
The,O
MLP-ANN,B-DeepLearning
contains,O
64,O
neurons,B-DeepLearning
in,O
the,O
input,B-DeepLearning
layer,I-DeepLearning
64,O
element,O
FCGR,O
6,O
neurons,B-DeepLearning
in,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
5,O
mutation,O
classes,O
and,O
1,O
normal,O
class,O
and,O
two,O
hidden,B-DeepLearning
layers,I-DeepLearning
with,O
the,O
neurons,B-DeepLearning
experimentally,O
varied,O
from,O
10,O
to,O
100,O
.,O
The,O
result,O
obtained,O
by,O
varying,O
the,O
neurons,B-DeepLearning
in,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
is,O
reported,O
in,O
Sect,O
3,O
.,O
Deep,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
DNN,B-DeepLearning
or,O
deep,B-DeepLearning
learning,I-DeepLearning
models,I-DeepLearning
were,O
proved,O
to,O
be,O
able,O
to,O
extract,O
automatically,O
useful,O
features,O
from,O
input,O
patterns,O
.,O
Under,O
this,O
framework,O
Long,B-DeepLearning
Short-Term,I-DeepLearning
Memory,I-DeepLearning
LSTM,B-DeepLearning
is,O
a,O
recurrent,B-DeepLearning
unit,I-DeepLearning
that,O
reads,O
a,O
sequence,O
one,O
step,O
at,O
a,O
time,O
and,O
can,O
exploit,O
long,O
range,O
relations,O
.,O
In,O
this,O
work,O
we,O
propose,O
a,O
DNN,B-DeepLearning
model,O
for,O
nucleosome,O
identification,O
on,O
sequences,O
from,O
three,O
different,O
species,O
.,O
Recently,O
deep,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
or,O
deep,B-DeepLearning
learning,I-DeepLearning
models,I-DeepLearning
were,O
proved,O
to,O
be,O
able,O
to,O
automatically,O
extract,O
useful,O
features,O
from,O
input,O
patterns,O
with,O
no,O
a,O
priori,O
information,O
.,O
The,O
two,O
main,O
categories,O
of,O
deep,B-DeepLearning
neural,I-DeepLearning
models,I-DeepLearning
are,O
Convolutional,B-DeepLearning
Neural,I-DeepLearning
Networks,I-DeepLearning
CNN,B-DeepLearning
and,O
Recurrent,B-DeepLearning
Neural,I-DeepLearning
Networks,I-DeepLearning
RNN,B-DeepLearning
.,O
CNNs,B-DeepLearning
are,O
characterized,O
by,O
an,O
initial,B-DeepLearning
layer,I-DeepLearning
of,O
convolutional,B-DeepLearning
filters,I-DeepLearning
followed,O
by,O
a,O
non,O
Linearity,O
a,O
sub-sampling,O
and,O
a,O
fully,B-DeepLearning
connected,I-DeepLearning
layer,I-DeepLearning
which,O
realized,O
the,O
final,O
classification,O
.,O
Conversely,O
in,O
this,O
work,O
we,O
want,O
to,O
avoid,O
the,O
feature,O
extraction,O
step,O
in,O
order,O
to,O
fully,O
exploit,O
the,O
capabilities,O
of,O
DNNs,B-DeepLearning
making,O
use,O
of,O
a,O
convolutional,B-DeepLearning
layer,I-DeepLearning
for,O
extracting,O
features,O
from,O
local,O
sequences,O
of,O
nucleotides,O
and,O
an,O
LSTM,B-DeepLearning
to,O
take,O
into,O
account,O
longer-range,O
positional,O
information,O
.,O
Another,O
important,O
component,O
of,O
a,O
deep,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
is,O
the,O
max-pooling,B-DeepLearning
layer,O
that,O
usually,O
follows,O
the,O
recurrent,O
or,O
convolutional,B-DeepLearning
layers,I-DeepLearning
in,O
the,O
computation,O
flow,O
.,O
The,O
dropout,B-DeepLearning
layer,I-DeepLearning
randomly,O
sets,O
to,O
zero,O
the,O
output,O
from,O
the,O
preceding,O
layer,O
during,O
training,O
with,O
a,O
probability,O
p,O
given,O
as,O
a,O
fixed,O
parameter,O
.,O
When,O
p,O
=,O
0.5,O
it,O
is,O
equivalent,O
to,O
training,O
2|W|,O
networks,O
with,O
shared,O
parameters,O
where,O
|W|,O
is,O
the,O
number,O
of,O
neurons,B-DeepLearning
subject,O
to,O
dropout,O
.,O
This,O
results,O
in,O
a,O
strong,O
regularization,B-DeepLearning
effect,O
which,O
helps,O
in,O
preventing,O
overfitting,B-DeepLearning
.,O
We,O
propose,O
three,O
kind,O
of,O
architectures,O
obtained,O
by,O
the,O
composition,O
of,O
six,O
kinds,O
of,O
neural,B-DeepLearning
layers:,I-DeepLearning
a,O
convolutional,B-DeepLearning
layer,I-DeepLearning
a,O
max,B-DeepLearning
pooling,I-DeepLearning
layer,I-DeepLearning
a,O
dropout,B-DeepLearning
layer,I-DeepLearning
a,O
long,B-DeepLearning
short-term,I-DeepLearning
memory,I-DeepLearning
LSTM,B-DeepLearning
layer,O
a,O
fully,B-DeepLearning
connected,I-DeepLearning
layer,I-DeepLearning
and,O
a,O
softmax,B-DeepLearning
layer,O
.,O
The,O
Max,B-DeepLearning
Pooling,I-DeepLearning
operation,O
with,O
width,O
and,O
stride,B-DeepLearning
2,O
helps,O
to,O
capture,O
the,O
most,O
salient,O
features,O
extracted,O
by,O
the,O
previous,O
layer,O
and,O
reduces,O
the,O
output,O
size,O
from,O
145,O
to,O
72,O
vectors,O
.,O
The,O
Dropout,O
operation,O
with,O
probability,O
p,O
=,O
0.5,O
is,O
used,O
to,O
prevent,O
overfitting,B-DeepLearning
during,O
the,O
training,B-DeepLearning
phase,I-DeepLearning
.,O
We,O
notice,O
that,O
the,O
best,O
architecture,O
is,O
the,O
CONV-LSTM-FCX2,B-DeepLearning
.,O
We,O
have,O
proposed,O
a,O
novel,O
model,B-DeepLearning
parameter,I-DeepLearning
training,O
scheme,O
based,O
on,O
the,O
concepts,O
of,O
quantum,O
computing,O
.,O
We,O
apply,O
deep,B-DeepLearning
learning,I-DeepLearning
methods,I-DeepLearning
in,O
this,O
paper,O
namely,O
we,O
use,O
convolutional,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
CNNs,B-DeepLearning
for,O
description,O
and,O
prediction,O
of,O
the,O
red,O
blood,O
cells’,O
trajectory,O
which,O
is,O
crucial,O
in,O
modeling,O
of,O
a,O
blood,O
flow,O
.,O
Training,B-DeepLearning
and,I-DeepLearning
testing,I-DeepLearning
sets,I-DeepLearning
used,O
for,O
neural,B-DeepLearning
network,I-DeepLearning
are,O
extracted,O
from,O
simulations,O
which,O
differ,O
only,O
in,O
initial,O
seeding,B-DeepLearning
of,O
the,O
cells,O
.,O
Besides,O
using,O
convolution,B-DeepLearning
or,O
fully,B-DeepLearning
connected,I-DeepLearning
layers,I-DeepLearning
we,O
also,O
used,O
a,O
relatively,O
new,O
type,O
of,O
layers,O
the,O
dense,B-DeepLearning
convolution,I-DeepLearning
layers,I-DeepLearning
introduced,O
in,O
.,O
Used,O
neural,B-DeepLearning
network,I-DeepLearning
architecture,O
hyperparameters,B-DeepLearning
are,O
these:,O
Weights,B-DeepLearning
are,O
initialized,O
in,O
the,O
range,O
xavier,O
bias,B-DeepLearning
is,O
set,O
to,O
0.,O
Learning,B-DeepLearning
rate,I-DeepLearning
is,O
0.0002,O
λ1,O
=,O
λ2,O
=,O
0.000001,O
dropout,B-DeepLearning
=,O
0.02,O
and,O
minibatch,B-DeepLearning
size,O
is,O
32,O
.,O
The,O
training,B-DeepLearning
phase,I-DeepLearning
lasts,O
about,O
6,O
hours,O
for,O
more,O
complicated,O
network,O
architectures,O
.,O
The,O
convolution,B-DeepLearning
region,I-DeepLearning
of,O
the,O
CNNs,B-DeepLearning
includes,O
the,O
convolution,B-DeepLearning
the,O
activation,B-DeepLearning
and,O
the,O
pooling,B-DeepLearning
layers,I-DeepLearning
.,O
80%,O
400,O
Healthy,O
and,O
400,O
Sick,O
were,O
allocated,O
to,O
training,B-DeepLearning
and,I-DeepLearning
testing,I-DeepLearning
that,O
is,O
the,O
processes,O
of,O
extracting,O
the,O
attributes,O
and,O
optimizing,O
the,O
weights,B-DeepLearning
of,O
the,O
filters,O
.,O
20%,O
100,O
thermographies,O
in,O
each,O
class,O
were,O
reserved,O
for,O
blind,O
validation,B-DeepLearning
and,O
establishing,O
the,O
final,O
predictive,O
accuracy,B-DeepLearning
of,O
these,O
architectures,O
using,O
a,O
database,O
of,O
images,O
that,O
was,O
not,O
used,O
for,O
learning,O
training,B-DeepLearning
and,I-DeepLearning
testing,I-DeepLearning
.,O
Different,O
techniques,O
were,O
used,O
to,O
improve,O
the,O
accuracy:,B-DeepLearning
Learning,B-DeepLearning
rate,I-DeepLearning
tuning,O
which,O
controls,O
the,O
update,O
of,O
the,O
CNNs,B-DeepLearning
weights,O
.,O
This,O
parameter,B-DeepLearning
greatly,O
impacts,O
the,O
result,O
and,O
performance,O
of,O
the,O
CNN,B-DeepLearning
model,O
.,O
The,O
neural,B-DeepLearning
networks,I-DeepLearning
are,O
updated,O
via,O
the,O
stochastic,B-DeepLearning
gradient,I-DeepLearning
.,O
Data,O
Augmentation,O
that,O
consists,O
in,O
the,O
realization,O
of,O
different,O
random,O
operations,O
of,O
rotation,O
translation,O
and,O
zoom,O
on,O
the,O
images,O
to,O
avoid,O
overfitting,B-DeepLearning
and,O
improve,O
generalization,B-DeepLearning
.,O
It,O
is,O
applied,O
using,O
a,O
differential,O
learning,B-DeepLearning
rate,I-DeepLearning
that,O
is,O
introducing,O
three,O
different,O
and,O
successively,O
higher,O
values,O
of,O
the,O
learning,B-DeepLearning
rate,I-DeepLearning
thus,O
taking,O
into,O
account,O
the,O
differential,O
knowledge,O
of,O
the,O
layers,O
.,O
Therefore,O
although,O
Resnet50,B-DeepLearning
provided,O
the,O
highest,O
accuracy,B-DeepLearning
is,O
less,O
stable,O
than,O
Resnet,B-DeepLearning
34,I-DeepLearning
1.09%,O
vs,O
063%,O
.,O
Table,O
2,O
provides,O
the,O
corresponding,O
confusion,B-DeepLearning
matrices,I-DeepLearning
in,O
validation,B-DeepLearning
.,O
With,O
respect,O
to,O
the,O
tune,O
of,O
models’,O
hyper-parameters,B-DeepLearning
the,O
R,O
package,O
mlrMBO,O
was,O
used,O
to,O
perform,O
a,O
Bayesian,O
optimization,O
within,O
the,O
train,B-DeepLearning
set,I-DeepLearning
.,O
This,O
package,O
implements,O
a,O
Bayesian,O
optimization,O
of,O
black-box,O
functions,O
which,O
allows,O
to,O
find,O
faster,O
an,O
optimal,O
hyper-parameters,B-DeepLearning
setting,O
in,O
contrast,O
to,O
traditional,O
hyperparameters,B-DeepLearning
search,O
strategies,O
such,O
as,O
grid,B-DeepLearning
search,I-DeepLearning
highly,O
time,O
consuming,O
when,O
more,O
than,O
3,O
hyper-parameters,B-DeepLearning
are,O
tuned,O
or,O
random,B-DeepLearning
search,I-DeepLearning
not,O
efficient,O
enough,O
since,O
similar,O
or,O
non-sense,O
hyper-parameters,B-DeepLearning
settings,O
might,O
be,O
tested,O
.,O
Table,O
1,O
shows,O
the,O
average,O
AUC,B-DeepLearning
performance,O
standard,O
deviation,O
and,O
number,O
of,O
genes,O
retained,O
by,O
the,O
different,O
models,O
tested,O
over,O
the,O
test,O
sets,O
of,O
the,O
cross-validation,B-DeepLearning
setting,O
.,O
The,O
proposed,O
Convolutional,B-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
CNN,B-DeepLearning
is,O
consisting,O
of,O
two,O
parallel,O
convolutional,B-DeepLearning
layers,I-DeepLearning
taking,O
as,O
inputs,O
transversal,O
coronal,O
and,O
axial,O
slices,O
acquired,O
before,O
and,O
after,O
chemotherapy,O
for,O
each,O
patient,O
.,O
As,O
illustrated,O
in,O
Fig.,O
2,O
this,O
architecture,O
contains,O
two,O
similar,O
branches,O
each,O
one,O
contains,O
4,O
blocks,O
of,O
2D,B-DeepLearning
convolution,I-DeepLearning
followed,O
by,O
an,O
activation,B-DeepLearning
function,I-DeepLearning
ReLU,B-DeepLearning
and,O
a,O
Max,B-DeepLearning
pooling,I-DeepLearning
layer,O
.,O
In,O
the,O
first,O
and,O
second,O
blocks,O
32,O
kernels,B-DeepLearning
were,O
used,O
for,O
each,O
convolutional,B-DeepLearning
layer,I-DeepLearning
.,O
The,O
parallel,O
Deep,B-DeepLearning
learning,I-DeepLearning
architecture,O
was,O
applied,O
for,O
each,O
view,O
using,O
corresponding,O
slices,O
before,O
and,O
after,O
the,O
first,O
chemotherapy,O
.,O
Consequently,O
we,O
used,O
the,O
Stochastic,B-DeepLearning
Gradient,I-DeepLearning
Descent,I-DeepLearning
SGD,B-DeepLearning
with,O
a,O
learning,B-DeepLearning
rate,I-DeepLearning
of,O
00052,O
.,O
A,O
learning,B-DeepLearning
rate,I-DeepLearning
decay,O
of,O
3.46e−5,O
was,O
used,O
to,O
schedule,O
a,O
best,O
accuracy,B-DeepLearning
.,O
To,O
compile,O
the,O
model,O
a,O
categorical,O
cross,B-DeepLearning
entropy,I-DeepLearning
was,O
used,O
as,O
loss,B-DeepLearning
function,I-DeepLearning
and,O
standard,O
accuracy,O
was,O
used,O
as,O
a,O
metric,O
.,O
To,O
avoid,O
results’,O
bias,B-DeepLearning
a,O
5-Fold,O
stratified,O
cross,B-DeepLearning
validation,I-DeepLearning
with,O
AUC,B-DeepLearning
as,O
metric,O
was,O
used,O
.,O
Within,O
150,O
epochs,B-DeepLearning
with,O
5-fold,O
stratified,O
cross,B-DeepLearning
validation,I-DeepLearning
an,O
accuracy,B-DeepLearning
of,O
90.03,O
was,O
obtained,O
using,O
20%,O
of,O
3D,O
validation,B-DeepLearning
data,I-DeepLearning
.,O
An,O
overfitting,B-DeepLearning
was,O
observed,O
during,O
training,O
when,O
using,O
only,O
one,O
of,O
the,O
views,O
without,O
data,O
augmentation,O
.,O
Besides,O
the,O
work,O
we,O
did,O
on,O
building,O
other,O
types,O
of,O
agents,O
we,O
have,O
also,O
tried,O
to,O
explore,O
in,O
more,O
depth,O
different,O
cognitive,O
and,O
affective,O
models,O
of,O
agents,O
including,O
symbolic,O
BDI,O
models,O
as,O
well,O
as,O
neural,B-DeepLearning
network,I-DeepLearning
models,I-DeepLearning
.,O
While,O
we,O
are,O
defining,O
FSTs,O
and,O
after,O
having,O
introduced,O
the,O
use,O
of,O
HMMs,O
as,O
stochastic,O
FSTs,O
it,O
is,O
worth,O
noticing,O
that,O
regular,O
transduction,O
rules,O
can,O
also,O
be,O
implemented,O
in,O
the,O
form,O
of,O
so-called,O
multilayer,B-DeepLearning
perceptrons,I-DeepLearning
MLP,B-DeepLearning
,O
a,O
particular,O
type,O
of,O
artificial,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
.,O
Artificial,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
are,O
based,O
on,O
simplistic,O
models,O
for,O
biological,O
neuron,O
behavior,O
and,O
the,O
interconnections,O
between,O
these,O
neurons,O
.,O
Most,O
often,O
the,O
nonlinear,O
function,O
is,O
a,O
limiter,O
or,O
a,O
sigmoid,B-DeepLearning
function,O
.,O
The,O
MLP,B-DeepLearning
is,O
the,O
far,O
most,O
widely,O
used,O
network,O
.,O
It,O
is,O
composed,O
of,O
an,O
input,B-DeepLearning
layer,I-DeepLearning
and,O
an,O
output,B-DeepLearning
layer,I-DeepLearning
separated,O
by,O
one,O
or,O
more,O
hidden,B-DeepLearning
layers,I-DeepLearning
of,O
nodes,B-DeepLearning
with,O
each,O
layer,O
connected,O
to,O
the,O
next,O
layer,O
feeding,O
its,O
node,B-DeepLearning
values,O
forward,O
Fig.,O
24,O
.,O
In,O
many,O
domains,O
neural,B-DeepLearning
networks,I-DeepLearning
are,O
an,O
effective,O
alternative,O
to,O
statistical,O
methods,O
.,O
James,O
Henderson,O
has,O
identified,O
a,O
suitable,O
neural,B-DeepLearning
network,I-DeepLearning
architecture,O
for,O
natural,O
language,O
parsing,O
called,O
Simple,B-DeepLearning
Synchrony,I-DeepLearning
Networks,I-DeepLearning
SSNs,B-DeepLearning
which,O
he,O
discusses,O
in,O
chapter,O
6,O
A,O
Neural,B-DeepLearning
Network,I-DeepLearning
Parser,O
that,O
Handles,O
Sparse,O
Data,O
.,O
Because,O
neural,B-DeepLearning
networks,I-DeepLearning
learn,O
their,O
own,O
internal,O
representations‚,O
neural,B-DeepLearning
networks,I-DeepLearning
can,O
decide,O
automatically,O
what,O
features,O
to,O
count,O
and,O
how,O
reliable,O
they,O
are,O
for,O
estimating,O
the,O
desired,O
probabilities,O
.,O
This,O
generalization,B-DeepLearning
ability,O
is,O
a,O
result,O
of,O
using,O
a,O
neural,B-DeepLearning
network,I-DeepLearning
method,O
for,O
representing,O
sets,O
of,O
objects‚,O
called,O
Temporal,O
Synchrony,O
Variable,O
Binding,O
TSVB,O
Shastri,O
and,O
Ajjanagadde‚,O
1993,O
.,O
SRNs,B-DeepLearning
can,O
learn,O
generalizations,B-DeepLearning
over,O
positions,O
in,O
an,O
input,O
sequence,O
and,O
thus,O
can,O
handle,O
unbounded,O
input,O
sequences‚,O
which,O
has,O
made,O
them,O
of,O
interest,O
in,O
natural,O
language,O
processing,O
.,O
By,O
using,O
TSVB,O
to,O
represent,O
the,O
constituents,O
in,O
a,O
syntactic,O
structure‚,O
SSNs,B-DeepLearning
also,O
learn,O
generalizations,B-DeepLearning
over,O
structural,O
constituents,O
.,O
The,O
linguistic,O
relevance,O
of,O
this,O
class,O
of,O
generalizations,B-DeepLearning
is,O
what,O
accounts,O
for,O
the,O
fact,O
that,O
SSNs,B-DeepLearning
generalize,O
from,O
training,B-DeepLearning
set,I-DeepLearning
to,O
testing,B-DeepLearning
set,I-DeepLearning
in,O
an,O
appropriate,O
way‚,O
as,O
demonstrated,O
in,O
Section,O
4,O
.,O
In,O
this,O
section,O
we,O
briefly,O
outline,O
the,O
SSN,B-DeepLearning
architecture,O
and,O
how,O
it,O
can,O
be,O
used,O
to,O
estimate,O
the,O
parameters,B-DeepLearning
of,O
a,O
probability,O
model,O
.,O
Standard,O
pattern-recognition,O
neural,B-DeepLearning
networks,I-DeepLearning
such,O
as,O
Multi-Layered,B-DeepLearning
Perceptrons,I-DeepLearning
MLPs,B-DeepLearning
take,O
a,O
vector,O
of,O
real,O
values,O
as,O
input‚,O
compute,O
hidden,O
internal,O
representation,O
which,O
is,O
also,O
a,O
vector,O
of,O
real,O
values‚,O
and,O
output,O
a,O
third,O
vector,O
of,O
real,O
values,O
.,O
Simple,B-DeepLearning
Recurrent,I-DeepLearning
Networks,I-DeepLearning
extend,O
MLPs,B-DeepLearning
to,O
sequences,O
by,O
using,O
the,O
hidden,O
representations,O
as,O
representations,O
of,O
the,O
network’s,O
state,O
at,O
a,O
given,O
point,O
in,O
the,O
sequence,O
.,O
Simple,B-DeepLearning
Synchrony,I-DeepLearning
Networks,I-DeepLearning
extend,O
SRNs,B-DeepLearning
by,O
computing,O
one,O
of,O
these,O
sequences,O
for,O
each,O
object,O
in,O
a,O
set,O
of,O
objects,O
.,O
The,O
most,O
important,O
feature,O
of,O
any,O
learning,O
architecture,O
is,O
how,O
it,O
generalizes,B-DeepLearning
from,O
training,B-DeepLearning
data,I-DeepLearning
to,O
testing,B-DeepLearning
data,I-DeepLearning
.,O
SRNs,B-DeepLearning
are,O
popular,O
for,O
sequence,O
processing,O
because,O
they,O
inherently,O
generalize,O
over,O
sequence,O
positions,O
.,O
Because,O
inputs,O
are,O
fed,O
to,O
an,O
SRN,B-DeepLearning
one,O
at,O
a,O
time‚,O
and,O
the,O
same,O
trained,O
parameters,B-DeepLearning
called,O
link,O
weights,O
apply,O
at,O
every,O
time‚,O
information,O
learned,O
at,O
one,O
sequence,O
position,O
will,O
inherently,O
be,O
generalized,O
to,O
other,O
sequence,O
positions,O
.,O
This,O
generalization,B-DeepLearning
ability,O
manifests,O
itself,O
in,O
the,O
fact,O
that,O
SRNs,B-DeepLearning
can,O
handle,O
arbitrarily,O
long,O
sequences,O
.,O
This,O
generalization,B-DeepLearning
ability,O
manifests,O
itself,O
in,O
the,O
fact,O
that,O
these,O
networks,O
can,O
handle,O
arbitrarily,O
many,O
constituents‚,O
and,O
therefore,O
unbounded,O
phrase,O
structure,O
trees,O
.,O
After,O
the,O
parent,O
of,O
a,O
terminal,O
is,O
chosen,O
it,O
is,O
used,O
by,O
the,O
SSN,B-DeepLearning
to,O
estimate,O
the,O
parameters,O
for,O
latter,O
portions,O
of,O
the,O
sentence‚,O
including,O
latter,O
parent,O
estimates,O
.,O
We,O
also,O
bias,B-DeepLearning
the,O
network,B-DeepLearning
training,I-DeepLearning
by,O
providing,O
a,O
new-nonterminal,O
input,O
unit,O
.,O
To,O
test,O
the,O
ability,O
of,O
Simple,B-DeepLearning
Synchrony,I-DeepLearning
Networks,I-DeepLearning
to,O
handle,O
sparse,O
data,O
we,O
train,O
the,O
SSN,B-DeepLearning
parser,O
described,O
in,O
the,O
previous,O
section,O
on,O
a,O
relatively,O
small,O
set,O
of,O
sentences,O
and,O
then,O
test,O
how,O
well,O
it,O
generalizes,O
to,O
a,O
set,O
of,O
previously,O
unseen,O
sentences,O
.,O
This,O
process,O
can,O
be,O
continued,O
until,O
no,O
more,O
changes,O
are,O
made,O
but,O
to,O
avoid,O
over-fitting,B-DeepLearning
it,O
is,O
better,O
to,O
check,O
the,O
performance,O
of,O
the,O
network,O
on,O
a,O
validation,B-DeepLearning
set,I-DeepLearning
and,O
stop,O
training,O
when,O
the,O
performance,O
on,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
reaches,O
a,O
maximum,O
.,O
This,O
is,O
why,O
we,O
have,O
split,O
the,O
corpus,O
into,O
three,O
datasets,O
one,O
for,O
training,B-DeepLearning
one,O
for,O
validation,B-DeepLearning
and,O
one,O
for,O
testing,B-DeepLearning
.,O
This,O
technique,O
also,O
allows,O
multiple,O
versions,O
of,O
the,O
network,O
to,O
be,O
trained,O
and,O
then,O
evaluated,O
using,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
without,O
ever,O
using,O
the,O
testing,B-DeepLearning
set,I-DeepLearning
until,O
a,O
single,O
network,O
has,O
been,O
chosen,O
.,O
A,O
variety,O
of,O
hidden,B-DeepLearning
layer,I-DeepLearning
sizes,O
and,O
random,O
initial,O
weight,B-DeepLearning
seeds,I-DeepLearning
were,O
used,O
in,O
the,O
different,O
networks,O
.,O
Larger,O
hidden,B-DeepLearning
layers,I-DeepLearning
result,O
in,O
the,O
network,O
being,O
able,O
to,O
fit,B-DeepLearning
the,I-DeepLearning
training,I-DeepLearning
data,I-DeepLearning
more,O
precisely,O
but,O
can,O
lead,O
to,O
over-fitting,B-DeepLearning
and,O
therefore,O
bad,O
performance,O
on,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
.,O
From,O
the,O
multiple,O
networks,O
trained,O
the,O
best,O
network,O
was,O
chosen,O
on,O
the,O
basis,O
of,O
its,O
performance,O
on,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
and,O
this,O
one,O
network,O
was,O
used,O
in,O
testing,O
.,O
The,O
best,O
network,O
had,O
100,O
hidden,B-DeepLearning
units,I-DeepLearning
and,O
trained,O
for,O
a,O
total,O
of,O
145,O
passes,O
through,O
the,O
training,B-DeepLearning
set,I-DeepLearning
.,O
Because,O
this,O
process,O
does,O
not,O
require,O
a,O
validation,B-DeepLearning
set,I-DeepLearning
we,O
estimate,O
these,O
parameters,B-DeepLearning
using,O
the,O
combination,O
of,O
the,O
training,B-DeepLearning
set,I-DeepLearning
and,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
.,O
This,O
generalization,B-DeepLearning
performance,O
is,O
due,O
to,O
SSNs’,B-DeepLearning
ability,O
to,O
generalize,O
across,O
constituents,O
as,O
well,O
as,O
across,O
sequence,O
positions,O
plus,O
the,O
ability,O
of,O
neural,B-DeepLearning
networks,I-DeepLearning
in,O
general,O
to,O
learn,O
what,O
input,O
features,O
are,O
important,O
as,O
well,O
as,O
what,O
they,O
imply,O
about,O
the,O
output,O
.,O
In,O
particular,O
we,O
used,O
a,O
momentum,B-DeepLearning
of,O
0.9,O
and,O
weight,B-DeepLearning
decay,I-DeepLearning
regularization,B-DeepLearning
of,O
between,O
0.1,O
and,O
0.0.,O
Both,O
the,O
learning,B-DeepLearning
rate,I-DeepLearning
and,O
the,O
weight,B-DeepLearning
decay,I-DeepLearning
were,O
decreased,O
as,O
the,O
learning,O
proceeded,O
based,O
on,O
training,B-DeepLearning
error,I-DeepLearning
and,O
validation,B-DeepLearning
error,I-DeepLearning
respectively,O
.,O
We,O
mean,O
feature,O
here,O
in,O
the,O
sense,O
of,O
features,O
which,O
can,O
be,O
computed,O
from,O
discourse,O
as,O
input,O
to,O
machine,B-DeepLearning
learning,I-DeepLearning
algorithms,O
for,O
classification,O
tasks,O
such,O
as,O
topic,O
segmentation,O
.,O
Moreover,O
generic,O
tools,O
are,O
provided,O
for,O
iterating,O
over,O
discourses,O
processing,O
them,O
and,O
extracting,O
sets,O
of,O
feature,O
values,O
at,O
regular,O
intervals,O
which,O
can,O
then,O
be,O
piped,O
directly,O
into,O
learners,O
like,O
decision,O
trees,O
neural,B-DeepLearning
nets,I-DeepLearning
or,O
support,O
vector,O
machines,O
.,O
We,O
have,O
found,O
the,O
visualiser,O
to,O
be,O
invaluable,O
in,O
debugging,O
algorithms,O
for,O
feature,O
extractors,O
tweaking,O
parameter,B-DeepLearning
values,O
and,O
hypothesizing,O
new,O
interesting,O
features,O
.,O
A,O
variety,O
of,O
learning,B-DeepLearning
parameters,I-DeepLearning
were,O
explored,O
and,O
the,O
best-performing,O
parameter,B-DeepLearning
set,O
was,O
selected:,O
initial,O
Q,O
values,O
set,O
to,O
0,O
exploration,O
parameter,O
ε,O
=,O
0.2,O
and,O
the,O
learning,B-DeepLearning
rate,I-DeepLearning
α,O
set,O
to,O
1/k,O
where,O
k,O
is,O
the,O
number,O
of,O
visits,O
to,O
the,O
Qs,O
a,O
being,O
updated,O
.,O
Schmid,O
1994a,O
presents,O
a,O
neural,B-DeepLearning
network,I-DeepLearning
tagger,O
based,O
on,O
multilayer,B-DeepLearning
perceptron,I-DeepLearning
networks,I-DeepLearning
.,O
An,O
artificial,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
consist,O
of,O
simple,O
units,O
each,O
associated,O
with,O
an,O
activation,O
value,O
and,O
directed,O
links,O
for,O
passing,O
the,O
values,O
between,O
the,O
units,O
.,O
Activation,B-DeepLearning
values,I-DeepLearning
are,O
propagated,O
from,O
input,O
to,O
output,B-DeepLearning
layers,I-DeepLearning
.,O
At,O
each,O
unit,O
the,O
input,B-DeepLearning
activation,I-DeepLearning
values,I-DeepLearning
are,O
summed,O
and,O
a,O
bias,B-DeepLearning
parameter,O
is,O
added,O
.,O
The,O
network,O
learns,O
by,O
adapting,O
the,O
weights,B-DeepLearning
of,O
the,O
connections,O
between,O
units,O
until,O
the,O
correct,O
output,O
is,O
produced,O
.,O
In,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
all,O
units,O
have,O
a,O
value,O
of,O
zero,O
except,O
the,O
correct,O
unit,O
tag,O
which,O
gets,O
the,O
value,O
of,O
one,O
.,O
In,O
a,O
system,O
of,O
this,O
kind,O
tagging,O
a,O
word,O
means,O
i,O
copying,O
the,O
tag,O
probabilities,O
of,O
the,O
word,O
and,O
its,O
neighbours,O
into,O
the,O
input,B-DeepLearning
units,I-DeepLearning
and,O
ii,O
propagating,O
the,O
activations,O
to,O
the,O
output,B-DeepLearning
units,I-DeepLearning
.,O
We,O
will,O
first,O
discuss,O
the,O
acquisition,O
of,O
tagging,O
rules,O
using,O
supervised,B-DeepLearning
learning,I-DeepLearning
where,O
a,O
manually,O
tagged,O
corpus,O
is,O
available,O
to,O
be,O
used,O
as,O
a,O
'gold,O
standard',O
to,O
guide,O
learning,O
.,O
In,O
back-propagation,B-DeepLearning
learning,O
this,O
training,O
is,O
done,O
by,O
repeatedly,O
iterating,O
over,O
all,O
examples,O
comparing,O
for,O
each,O
example,O
the,O
output,O
predicted,O
by,O
the,O
network,O
random,O
at,O
first,O
to,O
the,O
desired,O
output,O
and,O
changing,O
connection,B-DeepLearning
weights,I-DeepLearning
between,O
network,O
nodes,O
in,O
such,O
a,O
way,O
that,O
performance,O
increases,O
.,O
Multilayer,B-DeepLearning
Perceptrons,I-DeepLearning
Rumelhart,O
et,O
al.,O
1986,O
are,O
the,O
most,O
popular,O
neural,B-DeepLearning
network,I-DeepLearning
architecture,O
.,O
The,O
activation,B-DeepLearning
rule,I-DeepLearning
is,O
a,O
local,O
rule,O
which,O
is,O
used,O
by,O
each,O
unit,O
to,O
compute,O
its,O
activation,O
.,O
Given,O
two,O
words,O
preceding,O
context,O
and,O
89,O
categories,O
the,O
network,O
has,O
an,O
input,B-DeepLearning
layer,I-DeepLearning
of,O
178,O
units,O
and,O
an,O
output,B-DeepLearning
layer,I-DeepLearning
of,O
89,O
units,O
.,O
Adding,O
a,O
hidden,B-DeepLearning
layer,I-DeepLearning
to,O
a,O
two-layer,O
network,O
did,O
not,O
improve,O
performance,O
.,O
Connectionist,O
approaches,O
also,O
require,O
the,O
computation,O
of,O
fewer,O
parameters,B-DeepLearning
weights,B-DeepLearning
than,O
statistical,O
models,O
N-gram,O
probabilities,O
which,O
becomes,O
especially,O
useful,O
when,O
considering,O
a,O
wider,O
context,O
than,O
trigrams,O
.,O
On,O
the,O
theoretical,O
side,O
there,O
is,O
a,O
need,O
for,O
more,O
insight,O
into,O
the,O
differences,O
and,O
similarities,O
in,O
how,O
generalization,B-DeepLearning
is,O
achieved,O
in,O
this,O
area,O
by,O
different,O
statistical,O
and,O
machine,B-DeepLearning
learning,I-DeepLearning
techniques,O
.,O
Most,O
emphasis,O
in,O
current,O
deep,B-DeepLearning
learning,I-DeepLearning
artificial,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
based,O
automatic,O
recognition,O
of,O
speech,O
is,O
put,O
on,O
deep,B-DeepLearning
net,I-DeepLearning
architectures,O
with,O
multiple,O
sequential,O
levels,O
of,O
processing,O
.,O
Current,O
state-of-the-art,O
stochastic,O
ASR,O
systems,O
often,O
estimate,O
the,O
likelihood,O
pX|W,O
by,O
a,O
discriminatively-trained,O
multi-layer,B-DeepLearning
perceptron,I-DeepLearning
artificial,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
MLP,B-DeepLearning
.,O
The,O
rule-based,O
algorithm,O
obtained,O
60.67%,O
splitting,O
accuracy,B-DeepLearning
at,O
word,O
level,O
and,O
94.31%,O
accuracy,B-DeepLearning
within,O
the,O
word,O
at,O
split,O
level,O
.,O
The,O
hyperparameters,B-DeepLearning
found,O
to,O
optimize,O
it,O
are,O
n,O
=,O
4,O
α,O
=,O
10−5,O
marker=true,O
.,O
Recently,O
there,O
has,O
been,O
a,O
renewed,O
interest,O
in,O
applying,O
neural,B-DeepLearning
networks,I-DeepLearning
ANNs,B-DeepLearning
to,O
speech,O
recognition,O
thanks,O
to,O
the,O
invention,O
of,O
deep,B-DeepLearning
neural,I-DeepLearning
nets,I-DeepLearning
.,O
It,O
treats,O
the,O
network,O
as,O
a,O
deep,B-DeepLearning
belief,I-DeepLearning
network,I-DeepLearning
DBN,B-DeepLearning
built,O
out,O
of,O
restricted,B-DeepLearning
Bolztmann,I-DeepLearning
machines,I-DeepLearning
RBMs,B-DeepLearning
and,O
optimizes,O
an,O
energy-based,O
target,O
function,O
using,O
the,O
contrastive,O
divergence,O
CD,O
algorithm,O
.,O
As,O
for,O
the,O
third,O
method,O
it,O
is,O
different,O
from,O
the,O
two,O
above,O
in,O
the,O
sense,O
that,O
in,O
this,O
case,O
it,O
is,O
not,O
the,O
training,B-DeepLearning
algorithm,I-DeepLearning
that,O
is,O
slightly,O
modified,O
but,O
the,O
neurons,O
themselves,O
.,O
Namely,O
the,O
usual,O
sigmoid,B-DeepLearning
activation,I-DeepLearning
function,I-DeepLearning
is,O
replaced,O
with,O
the,O
rectifier,B-DeepLearning
function,I-DeepLearning
max0,O
x,O
.,O
These,O
kinds,O
of,O
neural,B-DeepLearning
units,I-DeepLearning
have,O
been,O
proposed,O
by,O
Glorot,O
et,O
al.,O
and,O
were,O
successfully,O
applied,O
to,O
image,O
recognition,O
and,O
NLP,O
tasks,O
.,O
Rectified,B-DeepLearning
linear,I-DeepLearning
units,I-DeepLearning
were,O
also,O
found,O
to,O
improve,O
restricted,B-DeepLearning
Boltzmann,I-DeepLearning
machines,I-DeepLearning
.,O
It,O
has,O
been,O
shown,O
recently,O
that,O
a,O
deep,B-DeepLearning
rectifier,I-DeepLearning
network,I-DeepLearning
can,O
attain,O
the,O
same,O
phone,O
recognition,O
performance,O
as,O
that,O
for,O
the,O
pre-trained,B-DeepLearning
nets,I-DeepLearning
of,O
Mohamed,O
et,O
al.,O
4,B-DeepLearning
but,O
without,O
the,O
need,O
for,O
any,O
pre-training,B-DeepLearning
.,O
This,O
efficient,O
unsupervised,O
algorithm,O
first,O
described,O
in,O
can,O
be,O
used,O
for,O
learning,O
the,O
connection,B-DeepLearning
weights,I-DeepLearning
of,O
a,O
deep,B-DeepLearning
belief,I-DeepLearning
network,I-DeepLearning
DBN,B-DeepLearning
consisting,O
of,O
several,O
layers,O
of,O
restricted,B-DeepLearning
Boltzmann,I-DeepLearning
machines,I-DeepLearning
RBMs,B-DeepLearning
.,O
As,O
their,O
name,O
implies,O
RBMs,B-DeepLearning
are,O
a,O
variant,O
of,O
Boltzmann,B-DeepLearning
machines,I-DeepLearning
with,O
the,O
restriction,O
that,O
their,O
neurons,O
must,O
form,O
a,O
bipartite,O
graph,O
.,O
They,O
have,O
an,O
input,B-DeepLearning
layer,I-DeepLearning
representing,O
the,O
features,O
of,O
the,O
given,O
task,O
a,O
hidden,B-DeepLearning
layer,I-DeepLearning
which,O
has,O
to,O
learn,O
some,O
representation,O
of,O
the,O
input,O
and,O
each,O
connection,O
in,O
an,O
RBM,B-DeepLearning
must,O
be,O
between,O
a,O
visible,B-DeepLearning
unit,I-DeepLearning
and,O
a,O
hidden,B-DeepLearning
unit,I-DeepLearning
.,O
RBMs,B-DeepLearning
can,O
be,O
trained,O
using,O
the,O
one-step,B-DeepLearning
contrastive,I-DeepLearning
divergence,I-DeepLearning
CD,B-DeepLearning
algorithm,O
described,O
in,O
6,O
.,O
It,O
is,O
a,O
simple,O
algorithm,O
where,O
first,O
we,O
train,O
a,O
network,O
with,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
to,O
full,B-DeepLearning
convergence,I-DeepLearning
using,O
backpropagation,B-DeepLearning
.,O
Then,O
we,O
replace,O
the,O
softmax,B-DeepLearning
layer,O
by,O
another,O
randomly,O
initialized,O
hidden,B-DeepLearning
layer,I-DeepLearning
and,O
a,O
new,O
softmax,B-DeepLearning
layer,O
on,O
top,O
and,O
we,O
train,O
the,O
network,O
again,O
.,O
This,O
process,O
is,O
repeated,O
until,O
we,O
reach,O
the,O
desired,O
number,O
of,O
hidden,B-DeepLearning
layers,I-DeepLearning
.,O
Seide,O
et,O
al.,O
found,O
that,O
this,O
method,O
gives,O
the,O
best,O
results,O
if,O
one,O
performs,O
only,O
a,O
few,O
iterations,O
of,O
backpropagation,B-DeepLearning
in,O
the,O
pre-training,B-DeepLearning
phase,O
instead,O
of,O
training,O
to,O
full,O
convergence,B-DeepLearning
with,O
an,O
unusually,O
large,O
learn,B-DeepLearning
rate,I-DeepLearning
.,O
In,O
their,O
paper,O
they,O
concluded,O
that,O
this,O
simple,O
training,O
strategy,O
performs,O
just,O
as,O
well,O
as,O
the,O
much,O
more,O
complicated,O
DBN,B-DeepLearning
pre-training,B-DeepLearning
method,O
described,O
above,O
.,O
In,O
the,O
case,O
of,O
the,O
third,O
method,O
it,O
is,O
not,O
the,O
training,B-DeepLearning
algorithm,I-DeepLearning
but,O
the,O
neurons,O
that,O
are,O
slightly,O
modified,O
.,O
Instead,O
of,O
the,O
usual,O
sigmoid,B-DeepLearning
activation,I-DeepLearning
here,O
we,O
apply,O
the,O
rectifier,B-DeepLearning
function,I-DeepLearning
max0,I-DeepLearning
x,O
for,O
all,O
hidden,B-DeepLearning
neurons,I-DeepLearning
.,O
There,O
are,O
two,O
fundamental,O
differences,O
between,O
the,O
sigmoid,B-DeepLearning
and,O
the,O
rectifier,B-DeepLearning
functions,I-DeepLearning
.,O
One,O
is,O
that,O
the,O
output,O
of,O
rectifier,B-DeepLearning
neurons,I-DeepLearning
does,O
not,O
saturate,O
as,O
their,O
activity,O
gets,O
higher,O
.,O
Glorot,O
et,O
al.,O
conjecture,O
that,O
this,O
is,O
very,O
important,O
in,O
explaining,O
their,O
good,O
performance,O
in,O
deep,B-DeepLearning
nets:,I-DeepLearning
because,O
of,O
this,O
linearity,O
there,O
is,O
no,O
gradient,B-DeepLearning
vanishing,I-DeepLearning
effect,O
.,O
One,O
might,O
suppose,O
that,O
this,O
could,O
harm,O
optimization,O
by,O
blocking,O
gradient,B-DeepLearning
backpropagation,I-DeepLearning
but,O
the,O
experimental,O
results,O
do,O
not,O
support,O
this,O
hypothesis,O
.,O
It,O
seems,O
that,O
the,O
hard,O
nonlinearities,O
do,O
no,O
harm,O
as,O
long,O
as,O
the,O
gradient,O
can,O
propagate,O
along,O
some,O
paths,O
.,O
The,O
main,O
advantage,O
of,O
deep,B-DeepLearning
rectifier,I-DeepLearning
nets,I-DeepLearning
is,O
that,O
they,O
can,O
be,O
trained,O
with,O
the,O
standard,O
backpropagation,B-DeepLearning
algorithm,O
without,O
any,O
pre-training,B-DeepLearning
.,O
A,O
random,O
10%,O
of,O
the,O
training,B-DeepLearning
set,I-DeepLearning
was,O
held,O
out,O
for,O
validation,B-DeepLearning
purposes,O
and,O
this,O
block,O
of,O
data,O
will,O
be,O
referred,O
to,O
as,O
the,O
’development,B-DeepLearning
set’,I-DeepLearning
.,O
It,O
contains,O
about,O
28,O
hours,O
of,O
recordings,O
from,O
which,O
22,O
hours,O
were,O
selected,O
for,O
the,O
training,O
set,O
2,O
hours,O
for,O
the,O
development,O
set,O
and,O
4,O
hours,O
for,O
the,O
test,O
set,O
.,O
In,O
the,O
case,O
of,O
the,O
DBN-based,O
pre-training,B-DeepLearning
method,O
see,O
Section,O
2.1,O
we,O
applied,O
stochastic,B-DeepLearning
gradient,I-DeepLearning
descent,I-DeepLearning
i.e.,O
backpropagation,B-DeepLearning
training,O
with,O
a,O
mini-batch,B-DeepLearning
size,O
of,O
128,O
.,O
For,O
Gaussian-binary,O
RBMs,B-DeepLearning
we,O
ran,O
50,O
epochs,B-DeepLearning
with,O
a,O
fixed,O
learning,B-DeepLearning
rate,I-DeepLearning
of,O
0.002,O
while,O
for,O
binary-binary,O
RBMs,B-DeepLearning
we,O
used,O
30,O
epochs,B-DeepLearning
with,O
a,O
learning,B-DeepLearning
rate,I-DeepLearning
of,O
002,O
.,O
Then,O
to,O
fine-tune,O
the,O
pre-trained,B-DeepLearning
nets,O
again,O
backpropagation,B-DeepLearning
was,O
applied,O
with,O
the,O
same,O
mini-batch,B-DeepLearning
size,O
as,O
that,O
used,O
for,O
pre-training,B-DeepLearning
.,O
The,O
initial,O
learn,B-DeepLearning
rate,I-DeepLearning
was,O
set,O
to,O
0.01,O
and,O
it,O
was,O
halved,O
after,O
each,O
epoch,B-DeepLearning
when,O
the,O
error,O
on,O
the,O
development,B-DeepLearning
set,I-DeepLearning
increased,O
.,O
During,O
both,O
the,O
pretraining,B-DeepLearning
and,O
fine-tuning,O
phases,O
the,O
learning,O
was,O
accelerated,O
by,O
using,O
a,O
momentum,B-DeepLearning
of,O
0.9,O
except,O
for,O
the,O
first,O
epoch,B-DeepLearning
of,O
fine-tuning,O
which,O
did,O
not,O
use,O
the,O
momentum,B-DeepLearning
method,O
.,O
Turning,O
to,O
the,O
discriminative,O
pre-training,B-DeepLearning
method,O
see,O
Section,O
2.2,O
the,O
initial,O
learn,B-DeepLearning
rate,I-DeepLearning
was,O
set,O
to,O
0.01,O
and,O
it,O
was,O
halved,O
after,O
each,O
epoch,B-DeepLearning
when,O
the,O
error,O
on,O
the,O
development,B-DeepLearning
set,I-DeepLearning
increased,O
.,O
The,O
learn,B-DeepLearning
rate,I-DeepLearning
was,O
restored,O
to,O
its,O
initial,O
value,O
of,O
0.01,O
after,O
the,O
addition,O
of,O
each,O
layer,O
.,O
Furthermore,O
we,O
found,O
that,O
using,O
5,O
epochs,B-DeepLearning
of,O
backpropagation,B-DeepLearning
after,O
the,O
introduction,O
of,O
each,O
layer,O
gave,O
the,O
best,O
results,O
.,O
For,O
both,O
the,O
pre-training,O
and,O
fine-tuning,O
phases,O
we,O
used,O
a,O
batch,B-DeepLearning
size,I-DeepLearning
of,O
128,O
and,O
momentum,B-DeepLearning
of,O
0.8,O
except,O
for,O
the,O
first,O
epoch,B-DeepLearning
.,O
The,O
initial,O
learn,B-DeepLearning
rate,I-DeepLearning
for,O
the,O
fine-tuning,O
of,O
the,O
full,O
network,O
was,O
again,O
set,O
to,O
001,O
.,O
The,O
training,O
of,O
deep,B-DeepLearning
rectifier,I-DeepLearning
nets,I-DeepLearning
see,O
Section,O
2.3,O
did,O
not,O
require,O
any,O
pre-training,O
at,O
all,O
.,O
The,O
training,O
of,O
the,O
network,O
was,O
performed,O
using,O
backpropagation,B-DeepLearning
with,O
an,O
initial,O
learn,B-DeepLearning
rate,I-DeepLearning
of,O
0.001,O
and,O
a,O
batch,B-DeepLearning
size,I-DeepLearning
of,O
128,O
.,O
As,O
can,O
be,O
seen,O
the,O
three,O
training,O
methods,O
performed,O
very,O
similarly,O
on,O
the,O
test,O
set,O
the,O
only,O
exception,O
being,O
the,O
case,O
of,O
five,O
hidden,B-DeepLearning
layers,I-DeepLearning
where,O
the,O
rectifier,B-DeepLearning
net,I-DeepLearning
performed,O
slightly,O
better,O
.,O
It,O
also,O
significantly,O
outperformed,O
the,O
other,O
two,O
methods,O
on,O
the,O
development,B-DeepLearning
set,I-DeepLearning
.,O
We,O
mention,O
that,O
a,O
single,O
hidden,B-DeepLearning
layer,I-DeepLearning
net,O
with,O
the,O
same,O
amount,O
of,O
weights,B-DeepLearning
as,O
the,O
best,O
deep,B-DeepLearning
net,I-DeepLearning
yielded,O
237%,O
.,O
Similar,O
to,O
the,O
TIMIT,O
tests,O
2048,O
neurons,O
were,O
used,O
for,O
each,O
hidden,B-DeepLearning
layer,I-DeepLearning
with,O
a,O
varying,O
number,O
of,O
hidden,B-DeepLearning
layers,I-DeepLearning
.,O
The,O
error,O
rates,O
seem,O
to,O
saturate,O
at,O
4-5,O
hidden,B-DeepLearning
layers,I-DeepLearning
and,O
the,O
curves,O
for,O
the,O
three,O
methods,O
run,O
parallel,O
and,O
have,O
only,O
slightly,O
different,O
values,O
.,O
The,O
lowest,O
error,O
rate,O
is,O
attained,O
with,O
the,O
five-layer,O
rectifier,B-DeepLearning
network,I-DeepLearning
both,O
on,O
the,O
development,O
and,O
the,O
test,B-DeepLearning
sets,I-DeepLearning
.,O
The,O
iteration,O
count,O
we,O
applied,O
here,O
50,O
for,O
Gaussian,O
RBMs,B-DeepLearning
and,O
30,O
for,O
binary,O
RBMs,B-DeepLearning
is,O
an,O
average,O
value,O
and,O
follows,O
the,O
work,O
of,O
Seide,O
et,O
al,O
.,O
Discriminative,O
pre-training,O
is,O
also,O
much,O
faster,O
than,O
the,O
DBN-based,O
method,O
but,O
is,O
still,O
slower,O
than,O
rectifier,B-DeepLearning
nets,I-DeepLearning
.,O
Tuning,B-DeepLearning
the,I-DeepLearning
parameters,I-DeepLearning
so,O
that,O
the,O
two,O
systems,O
had,O
a,O
similar,O
real-time,O
factor,O
was,O
also,O
out,O
of,O
the,O
question,O
as,O
the,O
hybrid,O
model,O
was,O
implemented,O
on,O
a,O
GPU,O
while,O
the,O
HMM,O
used,O
a,O
normal,O
CPU,O
.,O
Here,O
we,O
compared,O
two,O
training,O
methods,O
and,O
a,O
new,O
type,O
of,O
activation,B-DeepLearning
function,I-DeepLearning
for,O
deep,B-DeepLearning
neural,I-DeepLearning
nets,I-DeepLearning
and,O
evaluated,O
them,O
on,O
a,O
large,O
vocabulary,O
recognition,O
task,O
.,O
The,O
three,O
algorithms,O
yielded,O
quite,O
similar,O
recognition,O
performances,O
but,O
based,O
on,O
the,O
training,O
times,O
deep,B-DeepLearning
rectifier,I-DeepLearning
networks,I-DeepLearning
seem,O
to,O
be,O
the,O
preferred,O
choice,O
.,O
While,O
the,O
resulting,O
speech,O
sound,O
likelihood,O
estimates,O
are,O
demonstrated,O
to,O
be,O
better,O
that,O
the,O
earlier,O
used,O
likelihoods,O
derived,O
by,O
generative,O
Gaussian,O
Mixture,O
Models,O
unexpected,O
signal,O
distortions,O
that,O
were,O
not,O
seen,O
in,O
the,O
training,B-DeepLearning
data,I-DeepLearning
can,O
still,O
make,O
the,O
acoustic,O
likelihoods,O
unacceptably,O
low,O
.,O
Here,O
we,O
compare,O
three,O
methods;,O
namely,O
the,O
unsupervised,O
pre-training,O
algorithm,O
of,O
Hinton,O
et,O
al.,O
a,O
supervised,B-DeepLearning
pre-training,I-DeepLearning
method,O
that,O
constructs,O
the,O
network,O
layer-by-layer,O
and,O
deep,B-DeepLearning
rectifier,I-DeepLearning
networks,I-DeepLearning
which,O
differ,O
from,O
standard,O
nets,O
in,O
their,O
activation,B-DeepLearning
function,I-DeepLearning
.,O
Overall,O
for,O
the,O
large,O
vocabulary,O
speech,O
recognition,O
task,O
we,O
study,O
here,O
deep,B-DeepLearning
rectifier,I-DeepLearning
networks,I-DeepLearning
offer,O
the,O
best,O
tradeoff,O
between,O
accuracy,O
and,O
training,B-DeepLearning
time,I-DeepLearning
.,O
In,O
this,O
new,O
proposed,O
approach,O
a,O
multi-layer,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
multi-layer,B-DeepLearning
perceptron,I-DeepLearning
is,O
used,O
to,O
learn,O
the,O
decision,B-DeepLearning
function,I-DeepLearning
that,O
will,O
then,O
be,O
used,O
to,O
select,O
the,O
words,O
.,O
For,O
training,O
the,O
neural,B-DeepLearning
network,I-DeepLearning
parameters,I-DeepLearning
we,O
have,O
to,O
associate,O
a,O
target,O
value,O
to,O
each,O
word,O
.,O
The,O
scores,O
produced,O
by,O
the,O
neural,B-DeepLearning
network,I-DeepLearning
module,O
will,O
then,O
be,O
used,O
to,O
sort,O
the,O
list,O
of,O
candidate,O
words,O
and,O
the,O
top,O
of,O
the,O
list,O
will,O
be,O
selected,O
to,O
define,O
the,O
recognition,O
vocabulary,O
.,O
Feature,O
vectors,O
and,O
associated,O
target,O
values,O
are,O
used,O
for,O
training,O
the,O
neural,B-DeepLearning
network:,I-DeepLearning
the,O
input-feature,O
vector,O
is,O
the,O
input,B-DeepLearning
layer,I-DeepLearning
36,O
input,B-DeepLearning
neurons;,I-DeepLearning
the,O
target,O
value,O
is,O
the,O
output,O
of,O
the,O
unique,O
output,B-DeepLearning
layer,I-DeepLearning
neuron,I-DeepLearning
.,O
There,O
is,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
containing,O
18,O
neurons,O
.,O
In,O
recent,O
years,O
feed,B-DeepLearning
forward,I-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
FFNN,B-DeepLearning
,O
attracted,O
attention,O
due,O
their,O
ability,O
to,O
overcome,O
biggest,O
disadvantage,O
of,O
n-gram,O
models:,O
even,O
when,O
the,O
ngram,O
is,O
not,O
observed,O
in,O
training,O
FFNN,O
estimates,O
probabilities,O
of,O
the,O
word,O
based,O
on,O
the,O
full,O
history,O
.,O
The,O
RNN,B-DeepLearning
is,O
going,O
further,O
in,O
model,O
generalization:,B-DeepLearning
instead,O
of,O
considering,O
only,O
the,O
several,O
previous,O
words,O
parameter,O
n,O
the,O
recursive,B-DeepLearning
weights,I-DeepLearning
are,O
assumed,O
to,O
represent,O
short,O
term,O
memory,O
.,O
Long,B-DeepLearning
Short-Term,I-DeepLearning
Memory,I-DeepLearning
LSTM,B-DeepLearning
neural,B-DeepLearning
network,I-DeepLearning
is,O
different,O
type,O
of,O
RNN,B-DeepLearning
structure,O
.,O
LSTM,B-DeepLearning
approved,O
themselves,O
in,O
various,O
applications,O
and,O
it,O
seems,O
to,O
be,O
very,O
promising,O
course,O
also,O
for,O
the,O
field,O
of,O
language,O
modelling,O
.,O
Typical,O
NN,B-DeepLearning
unit,O
consists,O
of,O
the,O
input,B-DeepLearning
activation,I-DeepLearning
which,O
is,O
transformed,O
to,O
output,B-DeepLearning
activation,I-DeepLearning
with,O
activation,B-DeepLearning
function,I-DeepLearning
usually,O
sigmoidal,B-DeepLearning
.,O
Firstly,O
the,O
activation,B-DeepLearning
function,I-DeepLearning
is,O
applied,O
to,O
all,O
gates,O
.,O
There,O
is,O
a,O
softmax,B-DeepLearning
function,I-DeepLearning
used,O
in,O
output,B-DeepLearning
layer,I-DeepLearning
to,O
produce,O
normalized,O
probabilities,O
.,O
Normalization,O
of,O
input,O
vector,O
which,O
is,O
generally,O
advised,O
for,O
neural,B-DeepLearning
networks,I-DeepLearning
is,O
not,O
needed,O
due,O
the,O
1-of-N,O
input,O
coding,O
.,O
All,O
models,O
were,O
trained,O
with,O
20,O
cells,O
in,O
hidden,B-DeepLearning
layer,I-DeepLearning
.,O
The,O
recurrent,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
language,O
model,O
RNNLM,O
originally,O
proposed,O
by,O
2,O
and,O
3,O
incorporates,O
the,O
time,O
dimension,O
by,O
expanding,O
the,O
input,B-DeepLearning
layer,I-DeepLearning
which,O
represents,O
the,O
current,O
input,O
word,O
with,O
the,O
previous,O
hidden,B-DeepLearning
layer,I-DeepLearning
.,O
Theoretically,O
recurrent,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
can,O
store,O
relevant,O
information,O
from,O
previous,O
time,O
steps,O
for,O
an,O
arbitrarily,O
long,O
period,O
of,O
time,O
making,O
it,O
possible,O
to,O
learn,O
long-term,O
dependencies,O
.,O
To,O
explain,O
how,O
our,O
approach,O
works,O
let,O
us,O
examine,O
the,O
operation,O
of,O
a,O
simple,O
perceptron,B-DeepLearning
model,O
.,O
Hence,O
if,O
the,O
weights,B-DeepLearning
of,O
the,O
feature,B-DeepLearning
extraction,I-DeepLearning
layer,I-DeepLearning
were,O
initialized,O
with,O
2D,O
DCT,O
or,O
Gabor,O
filter,O
coefficients,O
and,O
only,O
the,O
weights,O
of,O
the,O
hidden,O
and,O
output,B-DeepLearning
layers,I-DeepLearning
were,O
tuned,O
during,O
training,O
then,O
the,O
model,O
would,O
be,O
equivalent,O
to,O
a,O
more,O
traditional,O
system,O
and,O
incorporating,O
the,O
feature,O
extraction,O
step,O
into,O
the,O
system,O
would,O
be,O
just,O
an,O
implementational,O
detail,O
.,O
Usually,O
as,O
the,O
backpropagation,B-DeepLearning
algorithm,O
guarantees,O
only,O
a,O
locally,O
optimal,O
solution,O
initializing,O
the,O
model,O
with,O
weights,O
that,O
already,O
provide,O
a,O
good,O
solution,O
may,O
help,O
the,O
backpropagation,B-DeepLearning
algorithm,O
find,O
a,O
better,O
local,O
optimum,O
than,O
the,O
one,O
found,O
using,O
random,O
initial,O
values,O
.,O
We,O
should,O
add,O
that,O
the,O
same,O
weights,B-DeepLearning
are,O
applied,O
on,O
each,O
input,O
block,O
so,O
the,O
number,O
of,O
weights,B-DeepLearning
will,O
not,O
change,O
in,O
this,O
layer,O
.,O
It,O
consisted,O
of,O
a,O
hidden,O
feature,B-DeepLearning
extraction,I-DeepLearning
layer,I-DeepLearning
with,O
a,O
linear,B-DeepLearning
activation,I-DeepLearning
function,I-DeepLearning
a,O
hidden,B-DeepLearning
layer,I-DeepLearning
with,O
1000,O
neurons,O
with,O
the,O
sigmoid,B-DeepLearning
activation,I-DeepLearning
function,I-DeepLearning
and,O
an,O
output,B-DeepLearning
layer,I-DeepLearning
containing,O
softmax,B-DeepLearning
units,I-DeepLearning
.,O
The,O
number,O
of,O
output,B-DeepLearning
neurons,I-DeepLearning
was,O
set,O
to,O
the,O
number,O
of,O
classes,O
39,O
while,O
the,O
number,O
of,O
neurons,O
in,O
the,O
input,O
and,O
feature,B-DeepLearning
extraction,I-DeepLearning
layers,I-DeepLearning
varied,O
depending,O
on,O
how,O
many,O
neighbouring,O
patches,O
were,O
actually,O
used,O
.,O
The,O
neural,B-DeepLearning
net,I-DeepLearning
was,O
trained,O
with,O
random,B-DeepLearning
initial,I-DeepLearning
weights,I-DeepLearning
in,O
the,O
hidden,O
and,O
output,B-DeepLearning
layers,I-DeepLearning
using,O
standard,O
backpropagation,B-DeepLearning
on,O
90%,O
of,O
the,O
training,B-DeepLearning
data,I-DeepLearning
in,O
semi-batch,B-DeepLearning
mode,O
while,O
crossvalidation,B-DeepLearning
on,O
the,O
remaining,O
randomly,O
selected,O
10%,O
of,O
the,O
training,B-DeepLearning
set,I-DeepLearning
was,O
used,O
as,O
the,O
stopping,O
criterion,O
.,O
The,O
‘extreme,O
learning,O
machine’,O
of,O
Huang,O
et,O
al.,O
also,O
exploits,O
this,O
suprising,O
fact:,O
this,O
learning,O
model,O
is,O
practically,O
a,O
twolayer,B-DeepLearning
network,I-DeepLearning
where,O
both,O
layers,O
are,O
initialized,O
randomly,O
and,O
the,O
lowest,O
layer,O
is,O
not,O
trained,O
at,O
all,O
.,O
In,O
order,O
to,O
verify,O
how,O
the,O
whisper,O
can,O
be,O
recognized,O
by,O
the,O
ANN,B-DeepLearning
the,O
two,O
speakerdependent,O
ASRs,O
were,O
developed,O
with,O
MATLAB,O
Neural,B-DeepLearning
Network,I-DeepLearning
Toolbox,O
.,O
The,O
structures,O
of,O
these,O
ANNs,B-DeepLearning
were:,O
396,O
input,B-DeepLearning
nodes,I-DeepLearning
140,O
hidden,B-DeepLearning
neurons,I-DeepLearning
and,O
50,O
output,B-DeepLearning
neurons,I-DeepLearning
.,O
For,O
each,O
speaker,O
all,O
words,O
are,O
divided,O
into,O
three,O
parts:,O
60%,O
of,O
them,O
are,O
used,O
for,O
training,O
20%,O
for,O
validation,B-DeepLearning
and,O
20%,O
for,O
testing,O
.,O
The,O
training,O
development,B-DeepLearning
and,I-DeepLearning
test,I-DeepLearning
sets,I-DeepLearning
for,O
the,O
classification,O
task,O
were,O
not,O
selected,O
from,O
the,O
corpus,O
in,O
a,O
completely,O
random,O
manner,O
but,O
instead,O
the,O
division,O
respected,O
the,O
websites,O
i.e.,O
one,O
set,O
of,O
websites,O
was,O
denoted,O
the,O
training,O
set,O
another,O
–,O
development,B-DeepLearning
set,I-DeepLearning
and,O
the,O
third,O
–,O
test,B-DeepLearning
set,I-DeepLearning
.,O
The,O
ASR,O
system,O
uses,O
a,O
hybrid,O
Hidden,O
Markov,O
Model,O
HMM,O
and,O
Deep,B-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
DNN,O
architecture,O
and,O
a,O
general,O
550k,O
lexicon,O
.,O
The,O
DNN,B-DeepLearning
utilizes,O
five,O
hidden,B-DeepLearning
layers,I-DeepLearning
with,O
1024,O
neurons,B-DeepLearning
per,I-DeepLearning
layer,I-DeepLearning
and,O
a,O
learning,B-DeepLearning
rate,I-DeepLearning
of,O
008,O
.,O
The,O
ReLU,B-DeepLearning
function,O
is,O
used,O
as,O
the,O
activation,B-DeepLearning
function,I-DeepLearning
of,O
neurons,O
.,O
This,O
DNN,B-DeepLearning
is,O
trained,O
for,O
35,O
epochs,B-DeepLearning
using,O
300,O
h,O
of,O
speech,O
recordings,O
.,O
Recently,O
neural-network,B-DeepLearning
based,O
approaches,O
in,O
which,O
words,O
are,O
embedded,O
into,O
a,O
low-dimensional,O
space,O
appeared,O
and,O
became,O
to,O
be,O
used,O
in,O
lexical,O
semantic,O
tasks,O
.,O
Following,O
recent,O
advances,O
in,O
artificial,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
research,O
the,O
recognizer,O
employs,O
parametric,B-DeepLearning
rectified,I-DeepLearning
linear,I-DeepLearning
units,I-DeepLearning
PReLU,B-DeepLearning
word,O
embeddings,O
and,O
character-level,O
embeddings,O
based,O
on,O
gated,B-DeepLearning
linear,I-DeepLearning
units,I-DeepLearning
GRU,B-DeepLearning
.,O
LSTMs,B-DeepLearning
are,O
specially,O
shaped,O
units,O
of,O
artificial,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
designed,O
to,O
process,O
whole,O
sequences,O
.,O
Recently,O
a,O
gated,B-DeepLearning
linear,I-DeepLearning
unit,I-DeepLearning
GRU,B-DeepLearning
was,O
proposed,O
by,O
Sam,O
as,O
an,O
alternative,O
to,O
LSTM,B-DeepLearning
and,O
was,O
shown,O
to,O
have,O
similar,O
performance,O
while,O
being,O
less,O
computationally,O
demanding,O
.,O
Instead,O
regularized,B-DeepLearning
averaged,I-DeepLearning
perceptron,I-DeepLearning
we,O
use,O
parametric,B-DeepLearning
rectified,I-DeepLearning
linear,I-DeepLearning
units,I-DeepLearning
character-level,O
embeddings,O
and,O
dropout,B-DeepLearning
.,O
The,O
input,B-DeepLearning
layer,I-DeepLearning
is,O
connected,O
to,O
a,O
hidden,B-DeepLearning
layer,I-DeepLearning
of,O
parametric,B-DeepLearning
rectified,I-DeepLearning
linear,I-DeepLearning
units,I-DeepLearning
and,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
is,O
connected,O
to,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
which,O
is,O
a,O
softmax,B-DeepLearning
layer,I-DeepLearning
producing,O
probability,O
distribution,O
for,O
all,O
possible,O
named,O
entity,O
classes,O
in,O
BILOU,O
encoding,O
.,O
The,O
network,O
is,O
trained,O
with,O
AdaGrad,B-DeepLearning
and,O
we,O
use,O
dropout,B-DeepLearning
on,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
.,O
We,O
implemented,O
our,O
neural,B-DeepLearning
network,I-DeepLearning
in,O
Torch7,O
a,O
scientific,O
computing,O
framework,O
with,O
wide,O
support,O
for,O
machine,O
learning,O
algorithms,O
.,O
We,O
tuned,O
most,O
of,O
the,O
hyperparameters,B-DeepLearning
on,O
development,O
portion,O
of,O
CNEC,O
1.0,O
and,O
used,O
them,O
for,O
all,O
other,O
corpora,O
.,O
Notably,O
we,O
utilize,O
window,O
size,O
W,O
=,O
2,O
hidden,B-DeepLearning
layer,I-DeepLearning
of,O
200,O
nodes,O
dropout,B-DeepLearning
0.5,O
minibatches,B-DeepLearning
of,O
size,O
100,O
and,O
learning,B-DeepLearning
rate,I-DeepLearning
0.02,O
with,O
decay,O
.,O
All,O
reported,O
experiments,O
use,O
an,O
ensemble,O
of,O
5,O
networks,O
each,O
using,O
different,O
random,B-DeepLearning
seed,I-DeepLearning
with,O
the,O
resulting,O
distributions,O
being,O
an,O
average,O
of,O
individual,O
networks,O
distributions,O
.,O
A,O
work,O
most,O
similar,O
to,O
ours,O
also,O
proposed,O
neural,B-DeepLearning
network,I-DeepLearning
architecture,O
with,O
word,O
embeddings,O
and,O
character-level,O
embeddings,O
.,O
The,O
best,O
published,O
WER,O
on,O
CMUDict,O
at,O
present,O
is,O
demonstrated,O
in,O
using,O
Long,B-DeepLearning
Short-term,I-DeepLearning
Memory,I-DeepLearning
Recurrent,I-DeepLearning
Neural,I-DeepLearning
Networks,I-DeepLearning
LSTM,B-DeepLearning
combined,O
with,O
a,O
5-gram,O
graphone,O
language,O
model,O
.,O
We,O
also,O
use,O
the,O
exact,O
same,O
split,O
of,O
90,O
%,O
training,B-DeepLearning
data,I-DeepLearning
and,O
10,O
%,O
test,B-DeepLearning
data,I-DeepLearning
as,O
in,O
9,O
and,O
thus,O
our,O
results,O
are,O
directly,O
comparable,O
to,O
theirs,O
.,O
Hierarchical,O
softmax,B-DeepLearning
and,O
related,O
procedures,O
that,O
involve,O
decomposing,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
into,O
classes,O
can,O
help,O
with,O
this,O
normalization,O
.,O
We,O
found,O
that,O
15,O
classes,O
optimized,O
perplexity,O
values,O
for,O
RNNLMs,B-DeepLearning
with,O
50,O
and,O
145,O
hidden,B-DeepLearning
nodes,I-DeepLearning
and,O
18,O
classes,O
optimized,O
perplexity,O
values,O
for,O
RNNLMs,B-DeepLearning
with,O
500,O
nodes,O
.,O
The,O
learning,B-DeepLearning
rate,I-DeepLearning
η,O
adaptation,O
scheme,O
is,O
managed,O
by,O
the,O
adaptive,B-DeepLearning
gradient,I-DeepLearning
methods,O
.,O
After,O
optimizing,O
on,O
the,O
development,B-DeepLearning
set,I-DeepLearning
η,O
was,O
fixed,O
to,O
0.1,O
and,O
the,O
dimensionality,O
of,O
the,O
latent,O
space,O
C,O
was,O
fixed,O
at,O
45,O
.,O
An,O
RNNLM,B-DeepLearning
with,O
145,O
hidden,B-DeepLearning
nodes,I-DeepLearning
has,O
about,O
the,O
same,O
number,O
of,O
parameters,O
as,O
CDLM,O
and,O
performs,O
0.1,O
perplexity,O
points,O
worse,O
than,O
CDLM,O
.,O
Increasing,O
the,O
hidden,B-DeepLearning
units,I-DeepLearning
for,O
RNNLM,B-DeepLearning
to,O
500,O
we,O
obtain,O
the,O
best,O
performing,O
RNNLM,B-DeepLearning
.,O
To,O
produce,O
better,O
performing,O
LMs,O
with,O
fewer,O
parameters,O
we,O
constructed,O
an,O
RNNLM,B-DeepLearning
with,O
50,O
hidden,O
units,O
which,O
when,O
linearly,O
combined,O
with,O
CDLM,O
CDLM+RNNLM,O
,O
outperforms,O
the,O
best,O
RNNLM,B-DeepLearning
using,O
less,O
than,O
half,O
as,O
many,O
parameters,O
.,O
The,O
architecture,O
for,O
this,O
kind,O
of,O
feature,O
extraction,O
consists,O
of,O
two,O
NNs,B-DeepLearning
trained,O
towards,O
phonetic,O
targets,O
.,O
The,O
first-stage,O
NN,B-DeepLearning
has,O
four,O
hidden,B-DeepLearning
layers,I-DeepLearning
with,O
1500,O
units,O
each,O
except,O
the,O
BN,O
layer,O
.,O
BN,O
layer’s,O
size,O
is,O
80,O
neurons,O
and,O
it,O
is,O
the,O
third,O
hidden,B-DeepLearning
layer,I-DeepLearning
.,O
Linear,O
regression,O
is,O
used,O
on,O
all,O
single,O
systems,O
for,O
arousal,O
and,O
all,O
single,O
systems,O
for,O
valence,O
except,O
for,O
processing,O
video,O
geometric,O
features,O
where,O
neural,B-DeepLearning
network,I-DeepLearning
with,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
is,O
used,O
topology:,O
948–474–3,O
.,O
We,O
trained,O
a,O
neural,B-DeepLearning
network,I-DeepLearning
with,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
with,O
topology,O
945–474–3,O
in,O
this,O
case,O
.,O
Our,O
approach,O
uses,O
a,O
bidirectional,B-DeepLearning
recurrent,I-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
BRNN,B-DeepLearning
since,O
speech,O
has,O
the,O
form,O
of,O
a,O
sequential,O
signal,O
with,O
complex,O
dependencies,O
between,O
the,O
different,O
time,O
steps,O
in,O
both,O
directions,O
.,O
Additionally,O
we,O
propose,O
an,O
alternative,O
layout,O
for,O
the,O
BRNN,B-DeepLearning
and,O
show,O
that,O
it,O
performs,O
better,O
on,O
that,O
specific,O
task,O
.,O
Usage,O
of,O
deep,B-DeepLearning
bidirectional,I-DeepLearning
GRU,I-DeepLearning
layers,O
can,O
be,O
found,O
in,O
the,O
work,O
of,O
Amodei,O
et,O
al.,O
where,O
for,O
example,O
up,O
to,O
seven,O
bidirectional,B-DeepLearning
GRU,I-DeepLearning
layers,O
are,O
used,O
and,O
even,O
combined,O
with,O
up,O
to,O
three,O
convolutional,B-DeepLearning
layers,I-DeepLearning
which,O
altogether,O
improved,O
the,O
performance,O
of,O
the,O
network,O
.,O
An,O
approach,O
for,O
speech,O
classification,O
solely,O
using,O
Convolutional,B-DeepLearning
Neural,I-DeepLearning
Networks,I-DeepLearning
CNN,B-DeepLearning
instead,O
of,O
recurrent,O
ones,O
can,O
be,O
seen,O
in,O
the,O
work,O
of,O
Milde,O
and,O
Biemann,O
.,O
GRU,B-DeepLearning
Networks,I-DeepLearning
are,O
a,O
variation,O
of,O
the,O
long,B-DeepLearning
short,I-DeepLearning
term,I-DeepLearning
memory,I-DeepLearning
LSTM,B-DeepLearning
networks,O
.,O
Conventional,O
RNN,B-DeepLearning
structures,O
propagate,O
information,O
only,O
forwards,O
in,O
time,O
.,O
In,O
this,O
context,O
bidirectional,B-DeepLearning
RNNs,I-DeepLearning
can,O
be,O
helpful,O
by,O
having,O
separate,O
layers,O
processing,O
the,O
two,O
different,O
directions,O
and,O
feeding,O
each,O
others,O
output,O
into,O
the,O
same,O
output,O
layer,O
as,O
it,O
is,O
depicted,O
in,O
Fig,O
.,O
Here,O
the,O
output,O
of,O
the,O
forward,B-DeepLearning
layer,I-DeepLearning
is,O
not,O
directly,O
propagated,O
towards,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
instead,O
it,O
serves,O
as,O
the,O
input,O
of,O
the,O
backward,B-DeepLearning
layer,I-DeepLearning
.,O
Deep,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
usually,O
come,O
with,O
a,O
large,O
amount,O
of,O
parameters,O
leaving,O
them,O
prone,O
to,O
overfitting,B-DeepLearning
.,O
One,O
straightforward,O
way,O
of,O
avoiding,O
that,O
is,O
using,O
Dropout,B-DeepLearning
.,O
Those,O
are,O
applied,O
by,O
multiplying,O
the,O
output,O
of,O
each,O
node,O
that,O
propagates,O
towards,O
a,O
dropout,B-DeepLearning
layer,I-DeepLearning
by,O
some,O
random,O
noise,O
with,O
each,O
batch,B-DeepLearning
of,I-DeepLearning
training,I-DeepLearning
data,I-DeepLearning
.,O
The,O
amount,O
of,O
deactivated,O
nodes,O
depends,O
on,O
the,O
dropout,B-DeepLearning
rate,I-DeepLearning
p,O
which,O
can,O
be,O
seen,O
as,O
the,O
distribution’s,O
parameter,O
in,O
the,O
binary,O
case,O
.,O
The,O
positive,O
effect,O
of,O
better,O
generalization,B-DeepLearning
capabilities,O
can,O
be,O
explained,O
in,O
two,O
ways,O
.,O
First,O
it,O
essentially,O
produces,O
an,O
ensemble,B-DeepLearning
of,I-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
and,O
therefore,O
producing,O
an,O
equally,O
averaged,O
result,O
over,O
those,O
.,O
We,O
use,O
the,O
training,O
test,O
and,O
development-test,B-DeepLearning
sets,I-DeepLearning
which,O
have,O
originally,O
been,O
provided,O
in,O
the,O
challenge,O
.,O
The,O
RNNs,B-DeepLearning
are,O
built,O
in,O
Python,O
using,O
the,O
Keras,O
framework,O
.,O
We,O
use,O
two,O
GRU,B-DeepLearning
layers,O
with,O
128,O
hidden,B-DeepLearning
states,I-DeepLearning
each,O
.,O
For,O
the,O
merged,O
BRNN,B-DeepLearning
those,O
are,O
both,O
connected,O
to,O
the,O
input,O
and,O
combine,O
their,O
results,O
to,O
a,O
dropout,B-DeepLearning
layer,I-DeepLearning
with,O
p,O
=,O
04,O
.,O
For,O
the,O
sequential,B-DeepLearning
BRNN,I-DeepLearning
the,O
first,O
GRU,B-DeepLearning
layer,I-DeepLearning
produces,O
another,O
time-dependent,O
sequence,O
which,O
is,O
then,O
fed,O
into,O
the,O
backward,B-DeepLearning
GRU,I-DeepLearning
layer,I-DeepLearning
.,O
After,O
each,O
of,O
those,O
follows,O
one,O
layer,O
of,O
dropout,B-DeepLearning
with,O
p,O
=,O
04,O
.,O
For,O
both,O
types,O
of,O
networks,O
we,O
finally,O
use,O
one,O
to,O
three,O
fully,B-DeepLearning
connected,I-DeepLearning
dense,I-DeepLearning
layers,O
with,O
again,O
128,O
hidden,B-DeepLearning
states,I-DeepLearning
each,O
eventually,O
followed,O
by,O
another,O
single-state,O
layer,O
which,O
produces,O
the,O
output,O
by,O
applying,O
the,O
sigmoid,B-DeepLearning
function,I-DeepLearning
which,O
is,O
also,O
used,O
as,O
the,O
inner,O
activation,O
of,O
the,O
GRU,B-DeepLearning
nodes,I-DeepLearning
.,O
The,O
remaining,O
activation,B-DeepLearning
functions,I-DeepLearning
between,O
each,O
two,O
nodes,O
are,O
defined,O
as,O
the,O
rectifier,O
or,O
relu,B-DeepLearning
function,I-DeepLearning
.,O
As,O
optimizer,O
we,O
use,O
Adam.,B-DeepLearning
In,O
earlier,O
stages,O
RMSprop,O
has,O
also,O
been,O
tried,O
but,O
it,O
clearly,O
proved,O
to,O
perform,O
worse,O
on,O
that,O
learning,O
task,O
and,O
also,O
oscillated,O
a,O
lot,O
making,O
it,O
useless,O
for,O
the,O
early,B-DeepLearning
stopping,I-DeepLearning
described,O
in,O
Sect.,O
44,O
.,O
The,O
loss,O
which,O
is,O
minimized,O
in,O
the,O
training,O
stage,O
is,O
the,O
binary,B-DeepLearning
cross-entropy,I-DeepLearning
.,O
The,O
model,O
is,O
then,O
trained,O
for,O
a,O
maximum,O
of,O
50,O
epochs,B-DeepLearning
and,O
evaluated,O
on,O
the,O
remaining,O
900,O
samples,O
of,O
the,O
development-test,B-DeepLearning
set,I-DeepLearning
after,O
each,O
iteration,O
.,O
Training,O
is,O
stopped,O
when,O
the,O
UAR,O
of,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
does,O
not,O
increase,O
for,O
10,O
epochs,B-DeepLearning
.,O
A,O
model,O
checkpoint,O
is,O
used,O
to,O
keep,O
track,O
of,O
the,O
weights,B-DeepLearning
which,O
have,O
been,O
used,O
to,O
reach,O
the,O
highest,O
UAR,B-DeepLearning
on,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
up,O
to,O
the,O
last,O
epoch,B-DeepLearning
.,O
Finally,O
we,O
obtain,O
a,O
measure,O
of,O
general,O
performance,O
by,O
using,O
the,O
highest,O
scoring,O
model,O
to,O
predict,O
the,O
labels,O
on,O
the,O
testing,B-DeepLearning
set,I-DeepLearning
.,O
Also,O
the,O
Gaussian,B-DeepLearning
dropout,I-DeepLearning
leads,O
to,O
slightly,O
higher,O
performance,O
than,O
the,O
binary,O
one,O
.,O
In,O
most,O
cases,O
the,O
network,O
with,O
two,O
fully,B-DeepLearning
connected,I-DeepLearning
layers,I-DeepLearning
after,O
the,O
recurrent,O
ones,O
achieves,O
the,O
highest,O
measures,O
.,O
Eventually,O
we,O
used,O
the,O
sequential,B-DeepLearning
BRNN,I-DeepLearning
with,O
two,O
dense,B-DeepLearning
layers,I-DeepLearning
and,O
Gaussian,B-DeepLearning
dropout,I-DeepLearning
after,O
being,O
trained,O
on,O
the,O
sets,O
specified,O
in,O
Sect.,O
4.4,O
to,O
predict,O
the,O
labels,O
of,O
the,O
testing,B-DeepLearning
set,I-DeepLearning
and,O
reached,O
a,O
UAR,B-DeepLearning
of,O
71.03,O
and,O
an,O
accuracy,O
of,O
71.30,O
percent,O
.,O
Also,O
it,O
became,O
clear,O
that,O
there,O
exists,O
a,O
variant,O
of,O
BRNNs,B-DeepLearning
which,O
has,O
to,O
our,O
knowledge,O
not,O
been,O
researched,O
thoroughly,O
yet,O
.,O
The,O
topic,O
of,O
the,O
paper,O
is,O
the,O
training,O
of,O
deep,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
which,O
use,O
tunable,O
piecewise-linear,B-DeepLearning
activation,I-DeepLearning
functions,I-DeepLearning
called,O
maxout,B-DeepLearning
for,O
speech,O
recognition,O
tasks,O
.,O
Maxout,B-DeepLearning
networks,I-DeepLearning
are,O
compared,O
to,O
the,O
conventional,O
fully-connected,B-DeepLearning
DNNs,I-DeepLearning
in,O
case,O
of,O
training,O
with,O
both,O
crossentropy,B-DeepLearning
and,O
sequence,B-DeepLearning
discriminative,I-DeepLearning
sMBR,O
criteria,O
.,O
The,O
clear,O
advantage,O
of,O
maxout,B-DeepLearning
networks,I-DeepLearning
over,O
DNNs,B-DeepLearning
is,O
demonstrated,O
when,O
using,O
the,O
cross-entropy,B-DeepLearning
criterion,O
on,O
both,O
corpora,O
.,O
It,O
is,O
also,O
argued,O
that,O
maxout,B-DeepLearning
networks,I-DeepLearning
are,O
prone,O
to,O
overfitting,B-DeepLearning
during,O
sequence,O
training,O
but,O
in,O
some,O
cases,O
it,O
can,O
be,O
successfully,O
overcome,O
with,O
the,O
use,O
of,O
the,O
KL-divergence,O
based,O
regularization,B-DeepLearning
.,O
The,O
greedy,B-DeepLearning
layerwise,I-DeepLearning
pretraining,I-DeepLearning
method,O
became,O
an,O
impulse,O
for,O
tempestuous,O
development,O
of,O
DNN,B-DeepLearning
training,O
.,O
The,O
pretraining,O
results,O
in,O
DNN,B-DeepLearning
weights,B-DeepLearning
initialization,O
that,O
facilitates,O
the,O
subsequent,O
finetuning,O
and,O
improves,O
its,O
quality,O
.,O
Nevertheless,O
the,O
fully,B-DeepLearning
connected,I-DeepLearning
feedforward,I-DeepLearning
deep,I-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
hereinafter,O
just,O
DNNs,B-DeepLearning
for,O
brevity,O
still,O
remain,O
the,O
workhorses,O
of,O
the,O
large,O
majority,O
of,O
ASR,O
systems,O
.,O
The,O
introduction,O
of,O
piecewise-linear,B-DeepLearning
ReLU,I-DeepLearning
rectified,B-DeepLearning
linear,I-DeepLearning
units,I-DeepLearning
activation,B-DeepLearning
functions,I-DeepLearning
made,O
it,O
possible,O
to,O
simplify,O
and,O
improve,O
the,O
optimization,O
process,O
during,O
DNN,B-DeepLearning
training,O
significantly,O
.,O
It,O
was,O
shown,O
that,O
DNNs,B-DeepLearning
with,O
ReLU,B-DeepLearning
activations,O
may,O
be,O
successfully,O
learned,O
without,O
layerwise,B-DeepLearning
pretraining,I-DeepLearning
.,O
However,O
the,O
fact,O
that,O
ReLU,B-DeepLearning
and,O
its,O
analogues,O
are,O
linear,O
almost,O
everywhere,O
may,O
also,O
result,O
in,O
overfitting,B-DeepLearning
and,O
instability,O
of,O
the,O
training,O
process,O
.,O
This,O
implies,O
the,O
necessity,O
of,O
using,O
effective,O
regularization,B-DeepLearning
techniques,O
.,O
Dropout,B-DeepLearning
can,O
be,O
treated,O
as,O
an,O
approximate,O
way,O
to,O
learn,O
the,O
exponentially,O
large,O
ensemble,O
of,O
different,O
neural,B-DeepLearning
nets,I-DeepLearning
with,O
subsequent,O
averaging,O
.,O
To,O
improve,O
efficiency,O
of,O
the,O
dropout,B-DeepLearning
regularization,I-DeepLearning
a,O
new,O
sort,O
of,O
tunable,O
piecewise-linear,B-DeepLearning
activation,I-DeepLearning
function,I-DeepLearning
called,O
maxout,B-DeepLearning
was,O
proposed,O
in,O
9,O
.,O
In,O
a,O
short,O
time,O
the,O
deep,B-DeepLearning
maxout,I-DeepLearning
networks,I-DeepLearning
DMN,B-DeepLearning
were,O
applied,O
to,O
speech,O
recognition,O
tasks,O
.,O
It,O
was,O
also,O
shown,O
that,O
dropout,B-DeepLearning
for,O
DMNs,B-DeepLearning
can,O
be,O
very,O
effective,O
in,O
an,O
annealed,O
mode,O
i.e.,O
if,O
the,O
dropout,B-DeepLearning
rate,I-DeepLearning
gradually,O
decreases,O
epoch-by-epoch,B-DeepLearning
.,O
We,O
apply,O
DMNs,B-DeepLearning
to,O
two,O
significantly,O
different,O
tasks,O
and,O
demonstrate,O
their,O
clear,O
superiority,O
over,O
conventional,O
DNNs,B-DeepLearning
under,O
cross-entropy,B-DeepLearning
CE,B-DeepLearning
training,O
.,O
Dropout,B-DeepLearning
proposed,O
in,O
is,O
a,O
regularization,B-DeepLearning
technique,I-DeepLearning
for,O
deep,B-DeepLearning
feedforward,I-DeepLearning
network,I-DeepLearning
training,O
which,O
is,O
effective,O
in,O
particular,O
for,O
training,O
network,O
with,O
a,O
large,O
amount,O
of,O
parameters,O
on,O
a,O
limited,O
size,O
dataset,O
.,O
In,O
the,O
original,O
form,O
of,O
dropout,B-DeepLearning
it,O
was,O
proposed,O
to,O
randomly,O
turn,O
off,O
half,O
of,O
neurons,O
per,O
every,O
training,O
example,O
.,O
When,O
the,O
neurons,O
with,O
piecewise-linear,B-DeepLearning
activation,I-DeepLearning
functions,O
like,O
ReLUx,B-DeepLearning
=,O
max0,O
x,O
are,O
used,O
the,O
input,O
space,O
is,O
divided,O
into,O
multiple,O
regions,O
where,O
data,O
is,O
linearly,O
transformed,O
by,O
the,O
network,O
.,O
From,O
this,O
point,O
of,O
view,O
using,O
of,O
dropout,B-DeepLearning
with,O
piecewise-linear,B-DeepLearning
activation,I-DeepLearning
functions,O
performs,O
the,O
more,O
exact,O
ensemble,O
averaging,O
than,O
with,O
activation,B-DeepLearning
functions,I-DeepLearning
of,O
nonzero,O
curvature,O
such,O
as,O
sigmoid,B-DeepLearning
.,O
The,O
effectiveness,O
of,O
DNNs,B-DeepLearning
with,O
ReLU,B-DeepLearning
neurons,O
trained,O
with,O
dropout,B-DeepLearning
was,O
demonstrated,O
on,O
many,O
tasks,O
from,O
different,O
domains,O
.,O
Maxout,B-DeepLearning
is,O
a,O
piecewise-linear,B-DeepLearning
activation,I-DeepLearning
function,O
which,O
was,O
proposed,O
to,O
improve,O
neural,B-DeepLearning
network,I-DeepLearning
training,O
with,O
dropout,B-DeepLearning
.,O
The,O
advantage,O
of,O
the,O
maxout,B-DeepLearning
activation,I-DeepLearning
function,I-DeepLearning
over,O
ReLU,B-DeepLearning
is,O
the,O
possibility,O
to,O
adjust,O
its,O
form,O
by,O
means,O
of,O
parameters,B-DeepLearning
tuning,I-DeepLearning
although,O
it,O
comes,O
at,O
the,O
cost,O
of,O
k-fold,B-DeepLearning
increasing,O
of,O
the,O
parameters,O
number,O
.,O
Maxout,B-DeepLearning
networks,I-DeepLearning
both,O
fully-connected,O
and,O
convolutional,B-DeepLearning
demonstrated,O
impressive,O
results,O
on,O
several,O
benchmark,O
tasks,O
from,O
the,O
computer,O
vision,O
domain,O
.,O
The,O
first,O
application,O
of,O
Deep,B-DeepLearning
Maxout,I-DeepLearning
Networks,I-DeepLearning
DMN,B-DeepLearning
to,O
speech,O
recognition,O
task,O
seems,O
to,O
be,O
done,O
in,O
February,O
and,O
in,O
March,O
where,O
it,O
was,O
shown,O
that,O
training,O
of,O
DMNs,B-DeepLearning
can,O
be,O
effective,O
even,O
without,O
using,O
dropout,B-DeepLearning
.,O
Nevertheless,O
the,O
training,O
of,O
DMNs,B-DeepLearning
can,O
be,O
successfully,O
combined,O
with,O
dropout,B-DeepLearning
regularization,I-DeepLearning
as,O
it,O
was,O
shown,O
here,O
.,O
There,O
it,O
was,O
proposed,O
to,O
use,O
not,O
the,O
conventional,O
dropout,B-DeepLearning
where,O
the,O
dropout,B-DeepLearning
rate,I-DeepLearning
is,O
constant,O
during,O
the,O
entire,O
training,O
but,O
the,O
annealed,B-DeepLearning
dropout,I-DeepLearning
AD,O
which,O
consists,O
of,O
the,O
gradually,O
decreasing,O
dropout,B-DeepLearning
rate,I-DeepLearning
according,O
to,O
the,O
linear,O
schedule,O
.,O
We,O
do,O
not,O
compare,O
Maxout,B-DeepLearning
+,O
AD,O
to,O
ReLU,B-DeepLearning
+,O
AD,O
because,O
in,O
our,O
experience,O
AD,O
training,O
of,O
ReLU,B-DeepLearning
networks,O
does,O
not,O
provide,O
significant,O
WER,O
reduction,O
it,O
is,O
also,O
observed,O
in,O
the,O
previous,O
paper,O
whilist,O
carefully,O
tuned,O
sigmoidal,B-DeepLearning
DNNs,I-DeepLearning
with,O
L2,B-DeepLearning
weight,I-DeepLearning
decay,I-DeepLearning
often,O
outperform,O
ReLU,B-DeepLearning
DNNs,I-DeepLearning
with,O
dropout,B-DeepLearning
and,O
other,O
types,O
of,O
regularization,O
.,O
When,O
the,O
model,O
was,O
trained,O
the,O
low-rank,O
factorization,O
based,O
on,O
SVD,O
of,O
the,O
last,O
hidden,B-DeepLearning
layer,I-DeepLearning
was,O
performed,O
and,O
the,O
model,O
was,O
fine-tuned,O
to,O
provide,O
bottleneck,O
features,O
hereinafter,O
SDBNs,O
Speaker-Dependent,O
BottleNeck,O
.,O
In,O
our,O
first,O
attempts,O
we,O
did,O
not,O
use,O
regularization,B-DeepLearning
.,O
Since,O
we,O
observed,O
that,O
the,O
cross-validation,B-DeepLearning
value,O
of,O
the,O
sMBR,O
criterion,O
either,O
increases,O
or,O
remains,O
constant,O
epoch-by-epoch,B-DeepLearning
we,O
concluded,O
that,O
the,O
model,O
is,O
overfit,B-DeepLearning
.,O
So,O
to,O
improve,O
ST,O
performance,O
an,O
effective,O
regularization,B-DeepLearning
is,O
required,O
.,O
We,O
tried,O
to,O
use,O
the,O
L1,B-DeepLearning
and,O
L2,B-DeepLearning
penalty,O
as,O
well,O
as,O
dropout,B-DeepLearning
and,O
F-smoothing,O
to,O
make,O
ST,O
work,O
on,O
Switchboard,O
however,O
none,O
of,O
these,O
approaches,O
succeeded,O
in,O
overfitting,B-DeepLearning
reduction,O
.,O
We,O
considered,O
the,O
use,O
of,O
maxout,B-DeepLearning
activation,I-DeepLearning
functions,I-DeepLearning
for,O
training,O
deep,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
as,O
acoustic,O
models,O
for,O
ASR,O
.,O
Using,O
two,O
English,O
speech,O
corpora,O
namely,O
CHiME,O
Challenge,O
2015,O
dataset,O
and,O
Switchboard,O
we,O
demonstrated,O
that,O
in,O
case,O
of,O
training,O
with,O
the,O
cross-entropy,B-DeepLearning
criterion,O
Deep,B-DeepLearning
Maxout,I-DeepLearning
Networks,I-DeepLearning
DMN,B-DeepLearning
are,O
superior,O
to,O
conventional,O
fully-connected,O
feedforward,B-DeepLearning
sigmoidal,I-DeepLearning
DNNs,I-DeepLearning
.,O
For,O
the,O
same,O
layer,B-DeepLearning
sizes,I-DeepLearning
the,O
number,O
of,O
DMN,B-DeepLearning
parameters,O
is,O
larger,O
than,O
that,O
of,O
DNN,B-DeepLearning
but,O
the,O
increase,O
in,O
DNN,B-DeepLearning
layer,I-DeepLearning
sizes,I-DeepLearning
is,O
unable,O
to,O
provide,O
the,O
comparable,O
accuracy,O
gain,O
.,O
We,O
also,O
found,O
that,O
sequence,O
discriminative,O
training,O
of,O
maxout,B-DeepLearning
networks,I-DeepLearning
is,O
prone,O
to,O
overfitting,B-DeepLearning
which,O
can,O
be,O
reduced,O
with,O
the,O
use,O
of,O
KLD-regularization,B-DeepLearning
.,O
The,O
performance,O
of,O
the,O
developed,O
models,O
was,O
examined,O
in,O
terms,O
of,O
the,O
Area,O
Under,O
the,O
Curve,O
AUC,O
derived,O
from,O
the,O
ROC,B-DeepLearning
curves,I-DeepLearning
as,O
well,O
as,O
Pearson,O
coefficient,O
R,O
between,O
the,O
predicted,O
and,O
the,O
actual,O
efficacy,O
.,O
Associative,B-DeepLearning
Neural,I-DeepLearning
Networks,I-DeepLearning
ASNN,B-DeepLearning
approach,O
and,O
fragment,O
descriptors,O
were,O
used,O
to,O
build,O
the,O
models,O
.,O
In,O
three,O
layers,O
neural,O
networks,O
each,O
neuron,O
in,O
the,O
initial,B-DeepLearning
layer,I-DeepLearning
corresponded,O
to,O
one,O
molecular,O
descriptor,O
.,O
Hidden,B-DeepLearning
layer,I-DeepLearning
contained,O
from,O
three,O
to,O
six,O
neurons,O
whereas,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
contained,O
one,O
for,O
STL,O
and,O
FN,O
or,O
11,O
MTL,O
neurons,O
corresponding,O
to,O
the,O
number,O
of,O
simultaneously,O
treated,O
properties,O
.,O
Each,O
model,O
was,O
validated,O
using,O
external,O
fivefold,B-DeepLearning
cross-validation,I-DeepLearning
procedure,O
.,O
Supervised,O
learning,O
is,O
usually,O
achieved,O
in,O
what,O
are,O
called,O
feed-forward,B-DeepLearning
NNs,I-DeepLearning
that,O
process,O
data,O
in,O
several,O
layers,O
consisting,O
of,O
varying,O
numbers,O
of,O
nodes,O
.,O
These,O
nodes,O
are,O
organized,O
as,O
input,B-DeepLearning
nodes,I-DeepLearning
several,O
layers,O
of,O
hidden,B-DeepLearning
nodes,I-DeepLearning
and,O
output,B-DeepLearning
nodes,I-DeepLearning
.,O
A,O
sliding,O
window,O
covers,O
60,O
nucleotides,O
which,O
is,O
calculated,O
to,O
240,O
input,B-DeepLearning
units,I-DeepLearning
to,O
the,O
neural,B-DeepLearning
network,I-DeepLearning
.,O
The,O
neural,B-DeepLearning
network,I-DeepLearning
structure,O
is,O
a,O
standard,O
three,O
layer,O
feedforward,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
.,O
This,O
kind,O
of,O
neural,B-DeepLearning
network,I-DeepLearning
has,O
several,O
names,O
such,O
as,O
multilayer,B-DeepLearning
perceptrons,I-DeepLearning
MLP,B-DeepLearning
feed,B-DeepLearning
forward,I-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
and,O
backpropagation,B-DeepLearning
neural,B-DeepLearning
network,I-DeepLearning
.,O
There,O
are,O
two,O
output,B-DeepLearning
units,I-DeepLearning
corresponding,O
to,O
the,O
donor,O
and,O
acceptor,O
splice,O
sites,O
128,O
hidden,B-DeepLearning
layer,I-DeepLearning
units,O
and,O
240,O
input,B-DeepLearning
units,I-DeepLearning
.,O
The,O
240,O
input,B-DeepLearning
units,I-DeepLearning
were,O
used,O
since,O
the,O
orthogonal,O
input,O
scheme,O
uses,O
four,O
inputs,O
each,O
nucleotide,O
in,O
the,O
window,O
.,O
The,O
neural,B-DeepLearning
network,I-DeepLearning
program,O
code,O
was,O
reused,O
from,O
a,O
previous,O
study,O
and,O
in,O
this,O
code,O
the,O
number,O
of,O
hidden,B-DeepLearning
units,I-DeepLearning
was,O
hard,O
coded,O
and,O
optimized,O
for,O
128,O
hidden,B-DeepLearning
units,I-DeepLearning
.,O
There,O
is,O
also,O
a,O
bias,B-DeepLearning
signal,O
added,O
to,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
and,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
.,O
The,O
activation,B-DeepLearning
function,I-DeepLearning
is,O
a,O
standard,O
sigmoid,B-DeepLearning
function,O
shown,O
in,O
Eq.,O
1,O
.,O
The,O
β,O
values,O
for,O
the,O
sigmoid,B-DeepLearning
functions,I-DeepLearning
are,O
0.1,O
for,O
both,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
activation,O
and,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
activation,O
.,O
When,O
doing,O
forward,O
calculations,O
and,O
backpropagation,B-DeepLearning
the,O
sigmoid,B-DeepLearning
function,O
is,O
called,O
repetitively,O
.,O
A,O
fast,O
and,O
effective,O
evaluation,O
of,O
the,O
sigmoid,B-DeepLearning
function,O
can,O
improve,O
the,O
overall,O
performance,O
considerably,O
.,O
To,O
improve,O
the,O
performance,O
of,O
the,O
sigmoid,B-DeepLearning
function,O
a,O
precalculated,O
table,O
for,O
the,O
exponential,O
function,O
is,O
used,O
.,O
There,O
is,O
no,O
momentum,B-DeepLearning
used,O
in,O
the,O
training,O
.,O
We,O
have,O
not,O
implemented,O
any,O
second,O
order,O
methods,O
to,O
help,O
the,O
convergence,B-DeepLearning
of,O
the,O
weights,B-DeepLearning
.,O
The,O
neural,B-DeepLearning
network,I-DeepLearning
training,O
is,O
done,O
using,O
standard,O
backpropagation,B-DeepLearning
.,O
The,O
training,O
was,O
done,O
in,O
three,O
sessions,O
and,O
for,O
each,O
session,O
we,O
chose,O
separate,O
but,O
constant,O
learning,B-DeepLearning
rates,I-DeepLearning
.,O
The,O
learning,B-DeepLearning
rate,I-DeepLearning
η,O
was,O
chosen,O
to,O
be,O
0.2,O
0.1,O
and,O
0.02,O
respectively,O
.,O
The,O
shown,O
indicators,O
are,O
computed,O
using,O
a,O
neural,B-DeepLearning
network,I-DeepLearning
which,O
has,O
been,O
trained,O
for,O
about,O
80,O
epochs,B-DeepLearning
with,O
a,O
learning,B-DeepLearning
rate,I-DeepLearning
of,O
02,O
.,O
The,O
best,O
performing,O
neural,B-DeepLearning
network,I-DeepLearning
achieved,O
a,O
correlation,O
coefficient,O
of,O
0552,O
.,O
The,O
MGN,O
works,O
in,O
this,O
case,O
as,O
a,O
discrete,O
time,O
cellular,O
neural,B-DeepLearning
network,I-DeepLearning
and,O
the,O
training,O
is,O
based,O
on,O
stochastic,B-DeepLearning
gradient,I-DeepLearning
descent,I-DeepLearning
as,O
described,O
in,O
the,O
paper,O
.,O
The,O
training,O
of,O
a,O
TPNN,O
is,O
based,O
on,O
a,O
combination,O
of,O
stochastic,B-DeepLearning
gradient,I-DeepLearning
descend,I-DeepLearning
and,O
back,B-DeepLearning
propagation,I-DeepLearning
with,O
several,O
improvements,O
that,O
make,O
the,O
training,O
of,O
the,O
shared,O
weights,O
feasible,O
and,O
that,O
were,O
reported,O
in,O
detail,O
in,O
the,O
context,O
of,O
training,O
CNNs,B-DeepLearning
for,O
pattern,O
recognition,O
.,O
In,O
stochastic,B-DeepLearning
gradient,I-DeepLearning
descent,I-DeepLearning
the,O
true,O
gradient,O
is,O
approximated,O
by,O
the,O
gradient,O
of,O
the,O
loss,B-DeepLearning
function,I-DeepLearning
which,O
is,O
evaluated,O
on,O
a,O
single,O
training,O
sample,O
.,O
Weight,B-DeepLearning
decay,I-DeepLearning
is,O
a,O
regularization,B-DeepLearning
method,O
that,O
penalizes,O
large,O
weights,B-DeepLearning
in,O
the,O
network,O
.,O
The,O
weight,B-DeepLearning
decay,I-DeepLearning
penalty,O
term,O
causes,O
the,O
insignificant,O
weights,B-DeepLearning
to,O
converge,O
to,O
zero,O
.,O
The,O
parameter,B-DeepLearning
µ,O
is,O
controlling,O
the,O
stepsize,B-DeepLearning
of,O
the,O
gradient,B-DeepLearning
descend,I-DeepLearning
.,O
The,O
initial,O
step,B-DeepLearning
size,I-DeepLearning
is,O
already,O
small,O
around,O
µ,O
=,O
0.01,O
and,O
it,O
is,O
decreased,O
after,O
each,O
training,O
epoch,B-DeepLearning
with,O
a,O
constant,O
factor,O
.,O
This,O
is,O
necessary,O
to,O
achieve,O
a,O
slow,O
convergence,B-DeepLearning
of,O
the,O
weights,B-DeepLearning
.,O
A,O
sweep,O
through,O
the,O
whole,O
data,O
set,O
is,O
called,O
one,O
epoch,B-DeepLearning
.,O
Up,O
to,O
1000,O
epochs,B-DeepLearning
are,O
necessary,O
to,O
train,O
the,O
TPNN,O
in,O
a,O
typical,O
experimental,O
setup,O
20,O
amino,O
acids,O
in,O
the,O
alphabet,O
peptides,O
of,O
length,O
5,O
to,O
10,O
30-50,O
training,O
samples,O
from,O
measurements,O
as,O
a,O
starting,O
set,O
.,O
The,O
slow,O
convergence,B-DeepLearning
of,O
the,O
error,O
is,O
a,O
consequence,O
of,O
the,O
relative,O
small,O
stepsize,B-DeepLearning
in,O
the,O
gradient,B-DeepLearning
descent,I-DeepLearning
but,O
it,O
is,O
necessary,O
in,O
order,O
to,O
get,O
overall,O
convergence,B-DeepLearning
of,O
the,O
weights,B-DeepLearning
.,O
It,O
is,O
well,O
known,O
that,O
neural,B-DeepLearning
network,I-DeepLearning
ensembles,I-DeepLearning
perform,O
better,O
in,O
terms,O
of,O
generalisation,B-DeepLearning
than,O
single,O
models,O
would,O
do,O
.,O
An,O
ensemble,O
of,O
TPNNs,O
consists,O
of,O
several,O
single,O
TPNN,O
models,O
that,O
are,O
trained,O
on,O
randomly,O
chosen,O
subsets,O
of,O
the,O
training,B-DeepLearning
data,I-DeepLearning
and,O
the,O
training,O
starts,O
with,O
random,O
weight,B-DeepLearning
initializations,I-DeepLearning
.,O
Two,O
analytical,O
models,O
have,O
been,O
used,O
to,O
fit,O
the,O
data,O
set,O
to,O
a,O
prognostic,O
index:,O
a,O
piecewise,O
linear,O
model,O
Cox,O
regression,O
also,O
known,O
as,O
proportional,O
hazards,O
and,O
a,O
flexible,O
model,O
consisting,O
of,O
Partial,O
Logistic,O
Artificial,B-DeepLearning
Neural,I-DeepLearning
Networks,I-DeepLearning
regularised,O
with,O
Automatic,O
Relevance,O
Determination,O
PLANN-ARD,O
.,O
If,O
these,O
features,O
are,O
stored,O
in,O
a,O
vector,O
f,O
=,O
f1...fh,O
and,O
if,O
we,O
represent,O
the,O
i-th,O
residue,O
in,O
the,O
sequence,O
as,O
ri,O
then,O
f,O
is,O
obtained,O
as:,O
where,O
N,O
h,O
is,O
a,O
non-linear,O
function,O
which,O
we,O
implement,O
by,O
a,O
two-layered,O
feedforward,B-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
with,O
h,O
non-linear,O
output,B-DeepLearning
units,I-DeepLearning
.,O
The,O
number,O
of,O
free,O
parameters,B-DeepLearning
in,O
the,O
overall,O
N1-NN,B-DeepLearning
can,O
be,O
controlled,O
by:,O
the,O
number,O
of,O
units,O
in,O
the,O
hidden,B-DeepLearning
layer,I-DeepLearning
of,O
the,O
sequence-to-feature,O
network,O
N,O
h,O
,O
N,O
H,O
f,O
;,O
the,O
number,O
of,O
hidden,B-DeepLearning
units,I-DeepLearning
in,O
the,O
feature-to-output,O
network,O
N,O
o,O
N,O
H,O
o,O
;,O
the,O
number,O
of,O
hidden,B-DeepLearning
states,I-DeepLearning
in,O
the,O
feature,O
vector,O
f,O
which,O
is,O
also,O
the,O
number,O
of,O
output,B-DeepLearning
units,I-DeepLearning
in,O
the,O
sequence-to-feature,O
network,O
Nf,O
,O
.,O
Each,O
training,O
is,O
conducted,O
by,O
10,O
fold-cross,B-DeepLearning
validation,I-DeepLearning
i.e.,O
10,O
different,O
sets,O
of,O
training,O
runs,O
are,O
performed,O
in,O
which,O
a,O
different,O
tenth,O
of,O
the,O
overall,O
set,O
is,O
reserved,O
for,O
testing,O
.,O
The,O
training,B-DeepLearning
set,I-DeepLearning
is,O
used,O
to,O
learn,O
the,O
free,O
parameters,B-DeepLearning
of,O
the,O
network,O
by,O
gradient,B-DeepLearning
descent,I-DeepLearning
while,O
the,O
validation,B-DeepLearning
set,I-DeepLearning
is,O
used,O
to,O
choose,O
model,O
and,O
hyperparameters,B-DeepLearning
network,B-DeepLearning
size,I-DeepLearning
and,O
architecture,O
i.e.,O
N,O
H,O
f,O
,O
Nf,O
and,O
N,O
H,O
o,O
,O
.,O
For,O
each,O
different,O
architecture,O
we,O
run,O
three,O
trainings,O
which,O
differ,O
only,O
in,O
the,O
training,O
vs.,O
validation,B-DeepLearning
split,I-DeepLearning
.,O
For,O
each,O
fold,O
the,O
three,O
networks,O
for,O
the,O
best,O
architecture,O
are,O
ensemble,O
averaged,O
and,O
evaluated,O
on,O
the,O
corresponding,O
test,B-DeepLearning
set,I-DeepLearning
.,O
Training,O
is,O
performed,O
by,O
gradient,B-DeepLearning
descent,I-DeepLearning
on,O
the,O
error,O
which,O
we,O
model,O
as,O
the,O
relative,O
entropy,O
between,O
the,O
target,O
class,O
and,O
the,O
output,O
of,O
the,O
network,O
.,O
The,O
overall,O
output,O
of,O
the,O
network,O
output,O
layer,O
of,O
N,O
o,O
,O
is,O
implemented,O
as,O
a,O
softmax,B-DeepLearning
function,O
while,O
all,O
internal,O
squashing,O
functions,O
are,O
implemented,O
as,O
hyperbolic,B-DeepLearning
tangents,I-DeepLearning
.,O
Training,O
terminates,O
when,O
either,O
the,O
walltime,O
on,O
the,O
server,O
is,O
reached,O
6,O
days,O
for,O
fungi,O
and,O
plants,O
10,O
days,O
for,O
animals,O
or,O
the,O
epoch,B-DeepLearning
limit,O
is,O
reached,O
40k,O
for,O
fungi,O
and,O
plants,O
and,O
20k,O
for,O
animals,O
.,O
The,O
gradient,O
is,O
updated,O
360,O
times,O
for,O
each,O
epoch,B-DeepLearning
or,O
once,O
every,O
2-6,O
examples,O
depending,O
on,O
the,O
set,O
and,O
the,O
examples,O
are,O
shuffled,O
between,O
epochs,B-DeepLearning
.,O
The,O
learning,B-DeepLearning
rate,I-DeepLearning
is,O
halved,O
every,O
time,O
a,O
reduction,O
of,O
the,O
error,O
is,O
not,O
observed,O
for,O
more,O
than,O
50,O
epochs,B-DeepLearning
.,O
Both,O
predictors,O
are,O
assessed,O
by,O
ten-fold,B-DeepLearning
cross-validation,I-DeepLearning
.,O
The,O
type,O
of,O
neural,B-DeepLearning
network,I-DeepLearning
with,O
which,O
we,O
performed,O
the,O
experiments,O
was,O
Multilayer,B-DeepLearning
Perceptron,I-DeepLearning
MLP,B-DeepLearning
because,O
the,O
results,O
obtained,O
with,O
other,O
types,O
of,O
networks,O
were,O
not,O
satisfactory,O
and,O
they,O
tended,O
to,O
be,O
slower,O
than,O
MLP,B-DeepLearning
.,O
The,O
preparatory,O
steps,O
for,O
conducting,O
the,O
experiments,O
consisted,O
in,O
determining:,O
a,O
the,O
size,O
of,O
the,O
training,O
and,O
testing,B-DeepLearning
set;,I-DeepLearning
b,O
the,O
error,B-DeepLearning
function;,I-DeepLearning
c,O
the,O
number,O
of,O
hidden,B-DeepLearning
units;,I-DeepLearning
d,O
the,O
activation,B-DeepLearning
functions,I-DeepLearning
for,O
the,O
hidden,O
and,O
the,O
output,B-DeepLearning
neurons;,I-DeepLearning
e,O
the,O
minimum,O
and,O
maximum,O
values,O
for,O
weight,B-DeepLearning
decay,I-DeepLearning
.,O
For,O
the,O
hidden,B-DeepLearning
neurons,I-DeepLearning
were,O
used,O
as,O
activation,B-DeepLearning
functions,I-DeepLearning
identity,O
logistic,O
tanh,B-DeepLearning
and,O
exponential,O
and,O
the,O
same,O
ones,O
were,O
chosen,O
for,O
the,O
output,B-DeepLearning
neurons,I-DeepLearning
.,O
The,O
error,B-DeepLearning
functions,I-DeepLearning
used,O
were,O
sum,B-DeepLearning
of,I-DeepLearning
squares,I-DeepLearning
and,O
cross,B-DeepLearning
entropy,I-DeepLearning
.,O
The,O
minimum,O
and,O
the,O
maximum,O
number,O
of,O
hidden,B-DeepLearning
units,I-DeepLearning
were,O
chosen,O
differently,O
for,O
each,O
experiment,O
because,O
we,O
conducted,O
several,O
experiments,O
which,O
had,O
different,O
number,O
of,O
inputs,O
.,O
The,O
larger,O
the,O
number,O
of,O
hidden,B-DeepLearning
units,I-DeepLearning
in,O
a,O
neural,B-DeepLearning
network,I-DeepLearning
model,O
the,O
stronger,O
the,O
model,O
is,O
the,O
more,O
capable,O
the,O
network,O
is,O
to,O
model,O
complex,O
relationships,O
between,O
the,O
inputs,O
and,O
the,O
target,O
variables,O
.,O
The,O
optimal,O
number,O
of,O
hidden,B-DeepLearning
units,I-DeepLearning
is,O
minimum,O
1/10,O
of,O
the,O
number,O
of,O
training,O
cases,O
and,O
maximum,O
1/5,O
but,O
we,O
have,O
varied,O
this,O
interval,O
.,O
The,O
use,O
of,O
decay,B-DeepLearning
weights,I-DeepLearning
for,O
hidden,B-DeepLearning
layer,I-DeepLearning
and,O
output,B-DeepLearning
layer,I-DeepLearning
was,O
preferred,O
in,O
order,O
to,O
prevent,O
overfitting,B-DeepLearning
thereby,O
potentially,O
improving,O
generalization,B-DeepLearning
performance,O
of,O
the,O
network,O
.,O
Weight,B-DeepLearning
decay,I-DeepLearning
or,O
weight,B-DeepLearning
elimination,O
are,O
often,O
used,O
in,O
MLP,B-DeepLearning
training,O
and,O
aim,O
to,O
minimize,O
a,O
cost,B-DeepLearning
function,I-DeepLearning
which,O
penalizes,O
large,O
weights,B-DeepLearning
.,O
These,O
techniques,O
tend,O
to,O
result,O
in,O
networks,O
with,O
smaller,O
weights,B-DeepLearning
.,O
The,O
minimum,O
chosen,O
weight,B-DeepLearning
decay,I-DeepLearning
was,O
0.0001,O
and,O
the,O
maximum,O
0001,O
.,O
To,O
perform,O
the,O
experiments,O
the,O
data,O
were,O
split,O
in,O
a,O
training,O
67,O
%,O
and,O
a,O
testing,B-DeepLearning
dataset,I-DeepLearning
33,O
%,O
.,O
As,O
error,B-DeepLearning
functions,I-DeepLearning
we,O
tested,O
the,O
cross,B-DeepLearning
entropy,I-DeepLearning
and,O
the,O
sum,B-DeepLearning
of,I-DeepLearning
squares,I-DeepLearning
.,O
The,O
weight,B-DeepLearning
decays,I-DeepLearning
in,O
both,O
the,O
hidden,O
and,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
varied,O
between,O
0.0001,O
and,O
0001,O
.,O
The,O
values,O
of,O
the,O
CV,O
criterion,O
Table,O
1,O
show,O
a,O
better,O
performance,O
in,O
correspondence,O
to,O
a,O
choice,O
of,O
6,O
hidden,B-DeepLearning
units,I-DeepLearning
and,O
decay,B-DeepLearning
parameter,I-DeepLearning
equal,O
to,O
0.01,O
that,O
we,O
therefore,O
used,O
.,O
Ten-fold,B-DeepLearning
cross-validation,I-DeepLearning
obtained,O
by,O
averaging,O
over,O
five,O
fits,O
for,O
various,O
values,O
of,O
the,O
number,O
of,O
hidden,O
units,O
H,O
and,O
of,O
the,O
decay,B-DeepLearning
parameter,I-DeepLearning
.,O
Scheme,O
of,O
a,O
multilayer,B-DeepLearning
perceptron,I-DeepLearning
with,O
the,O
layer,O
of,O
inputs,O
x1...xp,O
t,O
the,O
layer,O
of,O
hidden,B-DeepLearning
units,I-DeepLearning
z1...zH,O
and,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
here,O
represented,O
by,O
the,O
unique,O
response,O
h,O
.,O
Additionally,O
one,O
of,O
the,O
authors,O
recently,O
took,O
advantage,O
of,O
a,O
deep,B-DeepLearning
learning,I-DeepLearning
algorithm,O
built,O
on,O
a,O
multilayer,O
autoencoder,B-DeepLearning
neural,B-DeepLearning
network,I-DeepLearning
that,O
lead,O
to,O
interesting,O
prediction,O
results,O
in,O
reference,O
.,O
We,O
use,O
the,O
July,O
2009,O
version,O
of,O
the,O
datasets,O
for,O
analyzing,O
and,O
selecting,O
hyper-parameters,B-DeepLearning
.,O
Autoencoder,B-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
were,O
trained,O
using,O
the,O
free,O
GPU-accelerated,O
software,O
package,O
Torch7,O
using,O
stochastic,B-DeepLearning
gradient,I-DeepLearning
descent,I-DeepLearning
with,O
a,O
learning,B-DeepLearning
rate,I-DeepLearning
of,O
0.01,O
for,O
25,O
iterations,O
.,O
L2,B-DeepLearning
regularization,I-DeepLearning
was,O
used,O
on,O
all,O
weights,B-DeepLearning
which,O
were,O
initialized,O
randomly,O
from,O
the,O
uniform,O
distribution,O
.,O
The,O
hidden,B-DeepLearning
unit,I-DeepLearning
function,O
is,O
a,O
Sigmoid,B-DeepLearning
.,O
The,O
neural,B-DeepLearning
network,I-DeepLearning
is,O
a,O
modified,O
version,O
of,O
General,B-DeepLearning
Regression,I-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
GRNN,B-DeepLearning
used,O
as,O
a,O
classification,O
tool,O
.,O
In,O
order,O
to,O
perform,O
the,O
barcode,O
sequences,O
classification,O
we,O
introduce,O
a,O
modified,O
version,O
of,O
General,B-DeepLearning
Regression,I-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
GRNN,B-DeepLearning
that,O
use,O
alternatively,O
a,O
function,O
derived,O
from,O
Jaccard,O
distance,O
and,O
fractional,O
distance,O
instead,O
of,O
the,O
euclidean,O
one,O
to,O
compare,O
learned,O
prototypes,O
against,O
test,O
sequences,O
.,O
The,O
proposed,O
method,O
is,O
based,O
on,O
two,O
modified,O
versions,O
of,O
the,O
General,B-DeepLearning
Regression,I-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
.,O
The,O
General,B-DeepLearning
Regression,I-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
is,O
a,O
neural,B-DeepLearning
network,I-DeepLearning
created,O
for,O
regression,O
i.e.,O
the,O
approximation,O
of,O
a,O
dependent,O
variable,O
y,O
given,O
a,O
set,O
of,O
sample,O
x,O
y,O
where,O
x,O
is,O
the,O
independent,O
variable,O
.,O
Classification,O
results,O
in,O
terms,O
of,O
accuracy,B-DeepLearning
precision,B-DeepLearning
and,O
recall,B-DeepLearning
scores,O
have,O
been,O
compared,O
with,O
both,O
the,O
GRNN,B-DeepLearning
algorithm,O
using,O
J-function,O
and,O
the,O
SVM,O
classifier,O
.,O
Simple,B-DeepLearning
spiking,I-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
models,O
such,O
as,O
Integrate,O
and,O
fire,O
models,O
without,O
bio-realistic,O
features,O
were,O
simulated,O
in,O
the,O
older,O
generation,O
GPUs,O
.,O
All,O
above,O
described,O
methods,O
require,O
to,O
set,O
two,O
hyper-parameters:,B-DeepLearning
λ,O
and,O
α,O
controlling,O
the,O
sparsity,O
and,O
the,O
network,O
influence,O
respectively,O
.,O
Deep,B-DeepLearning
learning,I-DeepLearning
neural,I-DeepLearning
networks,I-DeepLearning
are,O
capable,O
to,O
extract,O
significant,O
features,O
from,O
raw,O
data,O
and,O
to,O
use,O
these,O
features,O
for,O
classification,O
tasks,O
.,O
In,O
this,O
work,O
we,O
present,O
a,O
deep,B-DeepLearning
learning,I-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
for,O
DNA,O
sequence,O
classification,O
based,O
on,O
spectral,O
sequence,O
representation,O
.,O
The,O
framework,O
is,O
tested,O
on,O
a,O
dataset,O
of,O
16S,O
genes,O
and,O
its,O
performances,O
in,O
terms,O
of,O
accuracy,B-DeepLearning
and,O
F1,O
score,O
are,O
compared,O
to,O
the,O
General,B-DeepLearning
Regression,I-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
already,O
tested,O
on,O
a,O
similar,O
problem,O
as,O
well,O
as,O
naive,O
Bayes,O
random,O
forest,O
and,O
support,O
vector,O
machine,O
classifiers,O
.,O
The,O
obtained,O
results,O
demonstrate,O
that,O
the,O
deep,B-DeepLearning
learning,I-DeepLearning
approach,I-DeepLearning
outperformed,O
all,O
the,O
other,O
classifiers,O
when,O
considering,O
classification,O
of,O
small,O
sequence,O
fragment,O
500,O
bp,O
long,O
.,O
Among,O
the,O
deep,B-DeepLearning
learning,I-DeepLearning
architecture,I-DeepLearning
it,O
is,O
usually,O
comprised,O
the,O
LeNet-5,B-DeepLearning
network,O
or,O
Convolutional,B-DeepLearning
Neural,I-DeepLearning
Network,I-DeepLearning
CNN,B-DeepLearning
a,O
neural,B-DeepLearning
network,I-DeepLearning
that,O
is,O
inspired,O
by,O
the,O
visual,O
system’s,O
structure,O
.,O
In,O
this,O
work,O
we,O
want,O
to,O
understand,O
if,O
the,O
convolutional,B-DeepLearning
network,I-DeepLearning
is,O
capable,O
to,O
identify,O
and,O
to,O
use,O
these,O
features,O
for,O
sequence,O
classification,O
outperforming,O
the,O
classifiers,O
proposed,O
in,O
the,O
past,O
.,O
The,O
one,O
used,O
in,O
this,O
work,O
is,O
a,O
modified,O
version,O
of,O
the,O
LeNet-5,B-DeepLearning
network,O
introduced,O
by,O
LeCun,O
et,O
al.,O
in,O
and,O
it,O
is,O
implemented,O
using,O
the,O
python,O
Theano,O
package,O
for,O
deep,B-DeepLearning
learning,I-DeepLearning
.,O
The,O
modified,O
LeNet-5,B-DeepLearning
proposed,O
network,O
is,O
made,O
of,O
two,O
lower,O
layers,O
of,O
convolutional,B-DeepLearning
and,O
max-pooling,B-DeepLearning
processing,O
elements,O
followed,O
by,O
two,O
traditional,O
fully,O
connected,O
Multi,B-DeepLearning
Layer,I-DeepLearning
Perceptron,I-DeepLearning
MLP,B-DeepLearning
processing,O
layers,O
so,O
that,O
there,O
are,O
6,O
processing,O
layers,O
.,O
The,O
max-pooling,B-DeepLearning
is,O
a,O
non-linear,O
down-sampling,B-DeepLearning
layer,I-DeepLearning
.,O
The,O
first,O
layer,O
of,O
convolutional,B-DeepLearning
kernels,I-DeepLearning
named,O
kernel,O
0,O
is,O
made,O
of,O
L,O
=,O
10,O
kernels,O
of,O
dimension,O
5,O
so,O
that,O
n,O
=,O
2,O
.,O
From,O
a,O
spectral,O
representation,O
vector,O
made,O
of,O
1024,O
components,O
this,O
layer,O
produces,O
10,O
vectors,O
of,O
1024,O
dimensions,O
that,O
the,O
pooling,B-DeepLearning
layer,I-DeepLearning
reduces,O
to,O
the,O
10,O
feature,O
maps,O
of,O
510,O
dimensions,O
.,O
These,O
vectors,O
are,O
the,O
input,O
for,O
the,O
second,O
convolutional,B-DeepLearning
layer,I-DeepLearning
.,O
The,O
second,O
layer,B-DeepLearning
of,I-DeepLearning
kernel,I-DeepLearning
kernel,O
1,O
,O
is,O
made,O
of,O
L,O
=,O
20,O
kernels,O
of,O
dimension,O
5,O
.,O
In,O
both,O
cases,O
the,O
max-pooling,B-DeepLearning
layer,O
has,O
dimension,O
2,O
.,O
Convolution,B-DeepLearning
and,O
maxpooling,B-DeepLearning
are,O
usually,O
considered,O
together,O
and,O
they,O
are,O
represented,O
in,O
the,O
lower,O
part,O
of,O
Fig.,O
2,O
as,O
two,O
highly,O
connected,O
blocks,O
.,O
The,O
two,O
upper,O
level,O
layers,O
corresponds,O
to,O
a,O
traditional,O
fully-connected,O
MLP:,B-DeepLearning
the,O
first,O
layer,O
of,O
the,O
MLP,B-DeepLearning
operates,O
on,O
the,O
total,O
number,O
of,O
output,O
from,O
the,O
lower,O
level,O
the,O
output,O
is,O
flattened,O
to,O
a,O
1-D,O
vector,O
and,O
the,O
total,O
number,O
of,O
units,O
in,O
the,O
Hidden,B-DeepLearning
Layer,I-DeepLearning
is,O
500,O
.,O
In,O
the,O
second,O
case,O
the,O
ten-fold,O
cross,B-DeepLearning
validation,I-DeepLearning
scheme,O
was,O
repeated,O
considering,O
as,O
test,O
set,O
the,O
sequence,O
fragments,O
of,O
shorter,O
size,O
500,O
bp,O
long,O
obtained,O
randomly,O
extracting,O
500,O
consecutive,O
nucleotides,O
from,O
the,O
original,O
full,O
length,O
sequences,O
.,O
The,O
CNN,B-DeepLearning
134,O
has,O
been,O
run,O
considering,O
two,O
different,O
kernels,O
sizes:,O
kernel,O
0,O
=,O
kernel,O
1,O
=,O
5,O
in,O
the,O
first,O
run;,O
kernel,O
0,O
=,O
25,O
kernel,O
1,O
=,O
15,O
in,O
the,O
second,O
run,O
.,O
In,O
both,O
configurations,O
the,O
training,B-DeepLearning
phase,I-DeepLearning
has,O
been,O
run,O
for,O
200,O
epochs,B-DeepLearning
.,O
The,O
spectral,O
representation,O
is,O
obtained,O
as,O
k-mers,O
frequencies,O
along,O
the,O
sequences;,O
the,O
CNN,B-DeepLearning
belongs,O
to,O
the,O
so,O
called,O
deep,B-DeepLearning
learning,I-DeepLearning
algorithms,O
.,O
We,O
designed,O
and,O
tested,O
some,O
topic,O
modeling,O
techniques,O
and,O
we,O
took,O
advantage,O
of,O
a,O
deep,B-DeepLearning
neural,I-DeepLearning
network,I-DeepLearning
approach,O
.,O
A,O
convolutional,B-DeepLearning
neural,I-DeepLearning
net,I-DeepLearning
learns,O
to,O
classify,O
patches,O
as,O
salient,O
long,O
looks,O
or,O
not,O
.,O
Two,O
output,B-DeepLearning
neurons,I-DeepLearning
were,O
connected,O
to,O
the,O
reinitialized,O
layer,O
then,O
training,O
followed,O
on,O
augmented,O
800,O
×,O
800,O
px,O
patches,O
for,O
10000,O
iterations,O
in,O
Caffe,O
.,O
Arguments,O
of,O
rkhs$new.,O
define,O
initial,O
values,O
of,O
the,O
functions,O
and,O
the,O
initial,O
value,O
of,O
the,O
l,B-DeepLearning
2,I-DeepLearning
norm,I-DeepLearning
weighting,I-DeepLearning
parameter,I-DeepLearning
.,O
