The,O
experimental,O
results,O
suggest,O
that,O
artificial,O
neural,B-DeepLearning
networks,I-DeepLearning
constitute,O
a,O
promising,O
alternative,O
to,O
deal,O
with,O
hierarchical,O
multilabel,O
classification,O
problems,O
.,O
The,O
proposed,O
method,O
,,O
named,O
here,O
HMC-LMLP,O
Hierarchical,O
Multilabel,O
Classification,O
with,O
Local,O
Multi-Layer,B-DeepLearning
Perceptron,I-DeepLearning
,,O
incrementally,O
trains,O
a,O
local,O
MLP,B-DeepLearning
network,O
for,O
each,O
hierarchical,O
level,O
,,O
using,O
the,O
back-propagation,B-DeepLearning
algorithm,O
.,O
First,O
,,O
a,O
MLP,B-DeepLearning
network,O
is,O
trained,O
for,O
the,O
first,O
hierarchical,O
level,O
.,O
This,O
network,O
uses,O
one,O
input,B-DeepLearning
layer,I-DeepLearning
,,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
and,O
one,O
output,B-DeepLearning
layer,I-DeepLearning
classes,O
.,O
After,O
training,O
this,O
network,O
,,O
a,O
new,O
network,O
with,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
and,O
one,O
output,B-DeepLearning
layer,I-DeepLearning
is,O
created,O
for,O
the,O
second,O
hierarchical,O
level,O
.,O
The,O
network,O
is,O
fully,B-DeepLearning
connected,I-DeepLearning
.,O
When,O
the,O
network,O
is,O
being,O
trained,O
for,O
a,O
hierarchical,O
level,O
,,O
the,O
synaptic,O
weights,B-DeepLearning
of,O
the,O
layers,O
corresponding,O
to,O
the,O
previous,O
levels,O
are,O
not,O
adjusted,O
,,O
because,O
their,O
adjustment,O
have,O
already,O
occurred,O
in,O
the,O
earlier,O
training,O
phases,O
of,O
the,O
network,O
,,O
corresponding,O
to,O
the,O
shallower,O
levels,O
.,O
In,O
conventional,O
networks,O
the,O
output,B-DeepLearning
layer,I-DeepLearning
Figure,O
1A,O
consists,O
of,O
sigmoidal,B-DeepLearning
activities,O
for,O
H,O
,,O
E,O
and,O
C,O
only,O
for,O
position,O
i,O
.,O
Network,O
training,O
data,O
was,O
prepared,O
from,O
the,O
PDB,B-DeepLearning
version,O
of,O
August,O
1999,O
.,O
Independent,O
network,O
predictions,O
arise,O
from,O
10-fold,B-DeepLearning
cross,I-DeepLearning
validated,I-DeepLearning
training,O
and,O
testing,O
of,O
1032,O
protein,O
sequences,O
at,O
both,O
primary,O
and,O
secondary,O
network,O
layers,O
.,O
This,O
may,O
be,O
done,O
with,O
a,O
rather,O
simple,O
feedforward,O
architecture,O
that,O
uses,O
2k,O
+,O
1,O
groups,O
of,O
20,O
input,B-DeepLearning
neurons,I-DeepLearning
to,O
encode,O
2k,O
+,O
1,O
amino,O
acids,O
each,O
of,O
the,O
20,O
amino,O
acids,O
is,O
encoded,O
by,O
20,B-DeepLearning
neurons,I-DeepLearning
in,O
a,O
unary,O
manner,O
,,O
a,O
hidden,B-DeepLearning
layer,I-DeepLearning
of,O
suitably,O
many,O
neurons,O
,,O
and,O
three,O
output,B-DeepLearning
neurons,I-DeepLearning
that,O
encode,O
in,O
unary,O
manner,O
the,O
three,O
classes,O
‘alpha-helix’,O
,,O
‘beta-sheet’,O
and,O
‘loop’,O
.,O
Both,O
networks,O
have,O
4000,O
hidden,B-DeepLearning
nodes,I-DeepLearning
and,O
3,O
output,B-DeepLearning
neurons,I-DeepLearning
corresponding,O
to,O
α-helix,O
,,O
β-strand,O
,,O
and,O
coil,O
of,O
the,O
middle,O
residue,O
in,O
the,O
sliding,O
window,O
,,O
respectively,O
.,O
This,O
N-to-1,O
network,O
has,O
150,O
hidden,B-DeepLearning
nodes,I-DeepLearning
and,O
predicts,O
three,O
output,O
values,O
as,O
well,O
.,O
The,O
experimental,O
results,O
showed,O
that,O
S2D,O
predicted,O
the,O
SS,O
populations,O
assigned,O
to,O
the,O
X-ray,O
structures,O
with,O
a,O
Q3,O
score,O
above,O
79%,O
and,O
identified,O
disordered,O
regions,O
with,O
an,O
accuracy,B-DeepLearning
about,O
85–88%,O
[,O
325,O
],O
.,O
As,O
the,O
first,O
trial,O
of,O
automatic,O
recognition,O
of,O
protein,O
subcellular,O
location,O
patterns,O
in,O
fluorescence,O
microscope,O
images,O
,,O
a,O
back-propagation,B-DeepLearning
neural,O
network,O
with,O
one,O
hidden,B-DeepLearning
layer,I-DeepLearning
and,O
20,O
hidden,B-DeepLearning
nodes,I-DeepLearning
was,O
trained,O
using,O
Zernike,O
moment,O
features,O
computed,O
from,O
the,O
2D,O
CHO,O
set,O
[,O
44,O
,,O
45,O
],O
.,O
The,O
neural,B-DeepLearning
network,I-DeepLearning
was,O
trained,O
on,O
the,O
training,B-DeepLearning
set,I-DeepLearning
and,O
the,O
training,O
was,O
stopped,O
when,O
the,O
sum,B-DeepLearning
of,I-DeepLearning
squared,I-DeepLearning
error,I-DeepLearning
on,O
the,O
stop,O
set,O
reached,O
a,O
minimum,O
.,O
The,O
test,O
set,O
was,O
then,O
used,O
to,O
evaluate,O
the,O
network.,O
Table,O
8.5,O
shows,O
the,O
confusion,B-DeepLearning
matrix,I-DeepLearning
averaged,O
over,O
eight,O
trials,O
.,O
The,O
average,O
classification,O
accuracy,B-DeepLearning
is,O
87%,O
on,O
eight,O
random,O
trials,O
and,O
the,O
corresponding,O
training,O
accuracy,B-DeepLearning
is,O
94%.,O
Data,O
from,O
reference,O
[,O
45,O
],O
.,O
Principal,B-DeepLearning
component,I-DeepLearning
analysis,I-DeepLearning
PCA,B-DeepLearning
,,O
probably,O
the,O
first,O
feature,O
recombination,O
method,O
adapted,O
for,O
data,O
mining,O
,,O
captures,O
the,O
linear,O
relationships,O
among,O
the,O
original,O
features,O
.,O
The,O
average,O
recall,B-DeepLearning
across,O
11,O
classes,O
after,O
50,B-DeepLearning
cross-validation,I-DeepLearning
trials,O
was,O
91%,O
,,O
which,O
is,O
as,O
good,O
as,O
the,O
2D,O
classification,O
result,O
.,O
The,O
same,O
neural,B-DeepLearning
network,I-DeepLearning
classifier,O
was,O
trained,O
on,O
SLF10,O
and,O
the,O
average,O
performance,O
is,O
shown,O
in,O
Table,O
8.12,O
after,O
50,O
cross-validation,B-DeepLearning
trials,O
.,O
Englehart,O
et,O
al.,O
[,O
26,O
],O
extracted,O
upper,O
limb,O
EMG,O
signals,O
from,O
four,O
channels,O
and,O
then,O
,,O
by,O
extracting,O
wavelet,O
coefficients,O
,,O
reduced,O
their,O
dimensions,O
by,O
PCA,B-DeepLearning
transform,O
,,O
and,O
finally,O
misclassification,O
rate,O
was,O
decreased,O
.,O
Traditionally,O
,,O
the,O
feed-forward,O
NN,B-DeepLearning
is,O
trained,O
using,O
a,O
gradient,B-DeepLearning
descent,I-DeepLearning
algorithm,O
such,O
as,O
back-propagation,B-DeepLearning
BPNN.,O
BPNN,O
optimizes,O
NNs,B-DeepLearning
by,O
randomly,O
initializing,O
the,O
weights,B-DeepLearning
and,O
adjusting,O
the,O
values,O
with,O
each,O
run,O
in,O
order,O
to,O
minimize,O
an,O
error,B-DeepLearning
function,I-DeepLearning
[,O
11,O
],O
.,O
This,O
is,O
different,O
from,O
linear,O
or,O
logistic,B-DeepLearning
regression,I-DeepLearning
which,O
only,O
search,O
for,O
the,O
coefficients,O
in,O
a,O
pre-specified,O
model,O
[,O
14,O
],O
.,O
To,O
adapt,O
the,O
weight,O
parameters,B-DeepLearning
in,O
the,O
MLPs,B-DeepLearning
ℵηℵφ,O
and,O
ℵβ,O
the,O
recurrent,O
NN,B-DeepLearning
is,O
unfolded,O
in,O
time,O
and,O
the,O
backpropagation,B-DeepLearning
algorithm,O
[,O
16,O
],O
is,O
used,O
to,O
calculate,O
the,O
gradient,O
for,O
all,O
weights,B-DeepLearning
.,O
