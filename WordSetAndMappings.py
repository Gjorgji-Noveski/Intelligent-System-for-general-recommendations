features = ['perceptron', 'feed forward', 'radial basis network', 'recurren neural network',
            'long short-term memory', 'long short term memory', 'long-short term memory',
            'long shortterm memory', 'gated recurrent unit', 'auto encoder', 'markov chain',
            'hopfield network', 'boltzman machine', 'deep belief network',
            'convolutional neural network', 'deconvolutional neural network', 'convolutional inverse graphics network',
            'probabilistic neural network', 'generative adversarial network', 'liquid state machine',
            'extreme learning machine', 'echo state network', 'deep residual network', 'kohonen network',
            'support vector machine', 'neural turing machine', 'cnn', 'rnn', 'lstm', 'gru', 'rbm', 'gan',
            'lsm', 'elm', 'esn', 'drn', 'svm', 'ntm',
            'linear activation function', 'rectified linear unit', 'sigmoid', 'gaussian error linear unit',
            'softmax', 'hyperbolic tangent function', 'softsign function', 'exponential linear unit',
            'leaky rectified linear unit', 'relu', 'gelu', 'tanh', 'elu', 'lrelu', 'leaky relu',
            'fully connected layer', 'fully-connected layer', 'recurrent layer', 'pooling layer',
            'convolutional layer', 'conv', 'convolution layer', 'deconvolutional layer', 'deconvolution layer',
            'dropout layer', 'softmax layer', 'subsampling layer', 'gru layer']

# words with multiple mappings
mappings = {
    'long short term memory': 'long short-term memory',
    'long-short term memory': 'long short-term memory',
    'long shortterm memory': 'long short-term memory',
    'lstm': 'long short-term memory',
    'gru': 'gated recurrent unit',
    'rnn': 'recurrent neural network',
    'cnn': 'convolutional neural network',
    'gan': 'generative adversarial network',
    'lsm': 'liquid state machine',
    'elm': 'extreme learning machine',
    'esn': 'echo state network',
    'drn': 'deep residual network',
    'svm': 'support vector machine',
    'ntm': 'neural turing machine',
    'relu': 'rectified linear unit',
    'gelu': 'gaussian error linear unit',
    'tanh': 'hyperbolic tangent function',
    'elu': 'exponential linear unit',
    'lrelu': 'leaky rectified linear unit',
    'leaky relu': 'leaky rectified linear unit',
    'fully-connected layer': 'fully connected layer',
    'conv': 'convolutional layer',
    'convolution layer': 'convolutional layer',
    'deconvolution layer': 'deconvolutional layer'
}

DATASET = ['number', 'subjects', 'dataset', 'patients', 'images', 'analyzed', 'downloaded', 'retrieved', 'created',
           'corpus', 'corpora', 'files']

ARCHITECTURE_TYPE_NO_ABBREVIATION = ['perceptron', 'feed forward', 'radial basis network', 'recurrent neural network',
                                     'long short-term memory', 'gated recurrent unit', 'auto encoder', 'markov chain',
                                     'hopfield network', 'boltzman machine', 'deep belief network',
                                     'convolutional neural network',
                                     'deconvolutional neural network', 'convolutional inverse graphics network',
                                     'probabilistic neural network', 'generative adversarial network',
                                     'liquid state machine',
                                     'extreme learning machine', 'echo state network', 'deep residual network',
                                     'kohonen network',
                                     'support vector machine', 'neural turing machine']

ARCHITECTURE_TYPE = ['perceptron', 'feed forward', 'radial basis network', 'recurrent neural network',
                     'long short-term memory', 'long short term memory', 'long-short term memory',
                     'long shortterm memory', 'gated recurrent unit', 'auto encoder', 'markov chain',
                     'hopfield network', 'boltzman machine', 'deep belief network', 'convolutional neural network',
                     'deconvolutional neural network', 'convolutional inverse graphics network',
                     'probabilistic neural network', 'generative adversarial network', 'liquid state machine',
                     'extreme learning machine', 'echo state network', 'deep residual network', 'kohonen network',
                     'support vector machine', 'neural turing machine', 'cnn', 'rnn', 'lstm', 'gru', 'rbm', 'gan',
                     'lsm',
                     'elm', 'esn', 'drn', 'svm', 'ntm']

ACTIVATION_FUNC_NO_ABBREVIATION = ['linear activation function', 'rectified linear unit', 'sigmoid',
                                   'gaussian error linear unit',
                                   'softmax', 'hyperbolic tangent function', 'softsign function',
                                   'exponential linear unit',
                                   'leaky rectified linear unit']

ACTIVATION_FUNC = ['linear activation function', 'rectified linear unit', 'sigmoid', 'gaussian error linear unit',
                   'softmax', 'hyperbolic tangent function', 'softsign function', 'exponential linear unit',
                   'leaky rectified linear unit', 'relu', 'gelu', 'tanh', 'elu', 'lrelu', 'leaky relu']

BUILDING_BLOCKS_NO_ABBREVIATION = ['fully connected layer', 'recurrent layer', 'pooling layer',
                                   'convolutional layer', 'deconvolutional layer',
                                   'dropout layer', 'softmax layer', 'subsampling layer', 'gru layer']

BUILDING_BLOCKS = ['fully connected layer', 'fully-connected layer', 'recurrent layer', 'pooling layer',
                   'convolutional layer', 'conv', 'convolution layer', 'deconvolutional layer', 'deconvolution layer',
                   'dropout layer', 'softmax layer', 'subsampling layer', 'gru layer']
